{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (KFold, \n",
    "                                     cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (classification_report,\n",
    "                             confusion_matrix,\n",
    "                             average_precision_score,\n",
    "                             precision_recall_curve,\n",
    "                             recall_score,\n",
    "                             f1_score)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import (RandomOverSampler,\n",
    "                                    SMOTE,\n",
    "                                    ADASYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_l</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_l</th>\n",
       "      <th>root_grate_l</th>\n",
       "      <th>root_other_l</th>\n",
       "      <th>trunk_wire_l</th>\n",
       "      <th>trnk_light_l</th>\n",
       "      <th>trnk_other_l</th>\n",
       "      <th>...</th>\n",
       "      <th>OnCurb</th>\n",
       "      <th>Harmful</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_l  num_problems  tree_dbh  root_stone_l  root_grate_l  \\\n",
       "0   Fair         1             0         3             0             0   \n",
       "1   Fair         1             1        21             1             0   \n",
       "2   Good         2             0         3             0             0   \n",
       "3   Good         2             1        10             1             0   \n",
       "4   Good         2             1        21             1             0   \n",
       "\n",
       "   root_other_l  trunk_wire_l  trnk_light_l  trnk_other_l  ...  OnCurb  \\\n",
       "0             0             0             0             0  ...       1   \n",
       "1             0             0             0             0  ...       1   \n",
       "2             0             0             0             0  ...       1   \n",
       "3             0             0             0             0  ...       1   \n",
       "4             0             0             0             0  ...       1   \n",
       "\n",
       "   Harmful  Helpful  Unsure  Damage  Bronx  Brooklyn  Manhattan  Queens  \\\n",
       "0        0        0       0       0      0         0          0       1   \n",
       "1        0        0       0       1      0         0          0       1   \n",
       "2        0        0       0       1      0         1          0       0   \n",
       "3        0        0       0       1      0         1          0       0   \n",
       "4        0        0       0       1      0         1          0       0   \n",
       "\n",
       "   Staten Island  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target and Response Variable, Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health_l') # keep the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488651, 24) (488651,)\n",
      "(162884, 24) (162884,)\n"
     ]
    }
   ],
   "source": [
    "# create targe and response variable\n",
    "y = tree_ml['health'].values\n",
    "X = tree_ml.drop('health', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6816502567014819\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "dummy_clf.fit(X, y)\n",
    "dc_pred = dummy_clf.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6807308893612776\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_freq = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf_freq.fit(X, y)\n",
    "dc_pred_freq = dummy_clf_freq.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "\n",
    "def logreg(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    print('Logistic Regression \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))\n",
    "    print()\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier\n",
    "\n",
    "def knn(X_train, X_test, y_train, y_test):\n",
    "    # using 6 neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print('KNN Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set: ', knn.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set: ', knn.score(X_test, y_test))\n",
    "    print()\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classificatin report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "\n",
    "def decision_tree(X_train, X_test, y_train, y_test):\n",
    "    decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    \n",
    "    print('Decision Tree Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "\n",
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Random Forest Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', rf.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', rf.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian naive bayes\n",
    "\n",
    "def gaussian(X_train, X_test, y_train, y_test):\n",
    "    gaussian = GaussianNB().fit(X_train, y_train)\n",
    "    y_pred = gaussian.predict(X_test)\n",
    "    \n",
    "    print('Gaussian Naive Bayes \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical naive bayes\n",
    "\n",
    "def categorical_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    categorical = CategoricalNB().fit(X_train, y_train)\n",
    "    y_pred = categorical.predict(X_test)\n",
    "    \n",
    "    print('Categorical Naive Bayes \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', categorical.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', categorical.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation - 5-fold - for later\n",
    "# cv_scores = cross_val_score(logreg, X, y, cv=5)\n",
    "# print('CV Scores: {}'.format(cv_scores))\n",
    "# print('Average 5-Fold CV Score: {}'.format(np.mean(cv_scores)))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Over Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Good': 396245, 'Fair': 396245, 'Poor': 396245})\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_ros, y_ros, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.4189007642578035\n",
      "Accuracy Score, Test Set:  0.4878195525650156\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 4117 10414  9576]\n",
      " [17498 71776 42808]\n",
      " [  904  2226  3565]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.17      0.18     24107\n",
      "        Good       0.85      0.54      0.66    132082\n",
      "        Poor       0.06      0.53      0.11      6695\n",
      "\n",
      "    accuracy                           0.49    162884\n",
      "   macro avg       0.37      0.42      0.32    162884\n",
      "weighted avg       0.72      0.49      0.57    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_ros, X_test, y_ros, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.4456199237004042\n",
      "Accuracy Score, Test Set:  0.44215515336067385\n",
      "\n",
      "Confusion Matrix: \n",
      " [[11179  9316  3612]\n",
      " [58072 59530 14480]\n",
      " [ 2991  2393  1311]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.15      0.46      0.23     24107\n",
      "        Good       0.84      0.45      0.59    132082\n",
      "        Poor       0.07      0.20      0.10      6695\n",
      "\n",
      "    accuracy                           0.44    162884\n",
      "   macro avg       0.35      0.37      0.31    162884\n",
      "weighted avg       0.70      0.44      0.51    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_ros, X_test, y_ros, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5155758011667866\n",
      "Accuracy Score, Test Set: 0.5152316986321553\n",
      "Confusion Matrix: \n",
      " [[ 6061 10715  7331]\n",
      " [24240 75149 32693]\n",
      " [ 1538  2444  2713]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.19      0.25      0.22     24107\n",
      "        Good       0.85      0.57      0.68    132082\n",
      "        Poor       0.06      0.41      0.11      6695\n",
      "\n",
      "    accuracy                           0.52    162884\n",
      "   macro avg       0.37      0.41      0.34    162884\n",
      "weighted avg       0.72      0.52      0.59    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_ros, X_test, y_ros, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5155505642552798\n",
      "Accuracy Score, Test Set: 0.5160727879963655\n",
      "Confusion Matrix: \n",
      " [[ 5995 10772  7340]\n",
      " [23613 75324 33145]\n",
      " [ 1509  2445  2741]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.19      0.25      0.22     24107\n",
      "        Good       0.85      0.57      0.68    132082\n",
      "        Poor       0.06      0.41      0.11      6695\n",
      "\n",
      "    accuracy                           0.52    162884\n",
      "   macro avg       0.37      0.41      0.34    162884\n",
      "weighted avg       0.72      0.52      0.59    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_ros, X_test, y_ros, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.39171051580040966\n",
      "Accuracy Score, Test Set: 0.7216792318459763\n",
      "Confusion Matrix: \n",
      " [[  1145  18142   4820]\n",
      " [  4922 114657  12503]\n",
      " [   230   4717   1748]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.05      0.08     24107\n",
      "        Good       0.83      0.87      0.85    132082\n",
      "        Poor       0.09      0.26      0.14      6695\n",
      "\n",
      "    accuracy                           0.72    162884\n",
      "   macro avg       0.37      0.39      0.35    162884\n",
      "weighted avg       0.71      0.72      0.71    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_ros, X_test, y_ros, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4151657013548015\n",
      "Accuracy Score, Test Set: 0.5525834336091943\n",
      "Confusion Matrix: \n",
      " [[ 6533 11698  5876]\n",
      " [29881 81087 21114]\n",
      " [ 1416  2892  2387]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.27      0.21     24107\n",
      "        Good       0.85      0.61      0.71    132082\n",
      "        Poor       0.08      0.36      0.13      6695\n",
      "\n",
      "    accuracy                           0.55    162884\n",
      "   macro avg       0.37      0.41      0.35    162884\n",
      "weighted avg       0.72      0.55      0.61    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_ros, X_test, y_ros, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Good': 396245, 'Fair': 396245, 'Poor': 396245})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_sm, y_sm = sm.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm, y_sm, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.4246093536406348\n",
      "Accuracy Score, Test Set:  0.47189410869084747\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 4927 10137  9043]\n",
      " [20547 68597 42938]\n",
      " [ 1159  2196  3340]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.20      0.19     24107\n",
      "        Good       0.85      0.52      0.64    132082\n",
      "        Poor       0.06      0.50      0.11      6695\n",
      "\n",
      "    accuracy                           0.47    162884\n",
      "   macro avg       0.36      0.41      0.32    162884\n",
      "weighted avg       0.72      0.47      0.56    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_sm, X_test, y_sm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.4400568671739286\n",
      "Accuracy Score, Test Set:  0.4453169126494929\n",
      "\n",
      "Confusion Matrix: \n",
      " [[11462  9397  3248]\n",
      " [59605 59884 12593]\n",
      " [ 3090  2416  1189]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.15      0.48      0.23     24107\n",
      "        Good       0.84      0.45      0.59    132082\n",
      "        Poor       0.07      0.18      0.10      6695\n",
      "\n",
      "    accuracy                           0.45    162884\n",
      "   macro avg       0.35      0.37      0.31    162884\n",
      "weighted avg       0.70      0.45      0.52    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_sm, X_test, y_sm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5106360963545281\n",
      "Accuracy Score, Test Set: 0.4982809852410304\n",
      "Confusion Matrix: \n",
      " [[ 5987 10361  7759]\n",
      " [23806 72353 35923]\n",
      " [ 1539  2334  2822]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.19      0.25      0.22     24107\n",
      "        Good       0.85      0.55      0.67    132082\n",
      "        Poor       0.06      0.42      0.11      6695\n",
      "\n",
      "    accuracy                           0.50    162884\n",
      "   macro avg       0.37      0.41      0.33    162884\n",
      "weighted avg       0.72      0.50      0.58    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_sm, X_test, y_sm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5106226366683911\n",
      "Accuracy Score, Test Set: 0.5019830063112399\n",
      "Confusion Matrix: \n",
      " [[ 5818 10535  7754]\n",
      " [22995 73124 35963]\n",
      " [ 1496  2376  2823]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.19      0.24      0.21     24107\n",
      "        Good       0.85      0.55      0.67    132082\n",
      "        Poor       0.06      0.42      0.11      6695\n",
      "\n",
      "    accuracy                           0.50    162884\n",
      "   macro avg       0.37      0.41      0.33    162884\n",
      "weighted avg       0.72      0.50      0.58    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_sm, X_test, y_sm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.3710759757220911\n",
      "Accuracy Score, Test Set: 0.1569890228628963\n",
      "Confusion Matrix: \n",
      " [[  2414   2248  19445]\n",
      " [ 10362  17508 104212]\n",
      " [   525    521   5649]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.10      0.13     24107\n",
      "        Good       0.86      0.13      0.23    132082\n",
      "        Poor       0.04      0.84      0.08      6695\n",
      "\n",
      "    accuracy                           0.16    162884\n",
      "   macro avg       0.36      0.36      0.15    162884\n",
      "weighted avg       0.73      0.16      0.21    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_sm, X_test, y_sm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4187173760341876\n",
      "Accuracy Score, Test Set: 0.5069804277891015\n",
      "Confusion Matrix: \n",
      " [[ 6955 10432  6720]\n",
      " [30959 72918 28205]\n",
      " [ 1519  2470  2706]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.29      0.22     24107\n",
      "        Good       0.85      0.55      0.67    132082\n",
      "        Poor       0.07      0.40      0.12      6695\n",
      "\n",
      "    accuracy                           0.51    162884\n",
      "   macro avg       0.37      0.41      0.34    162884\n",
      "weighted avg       0.72      0.51      0.58    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_sm, X_test, y_sm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADASYN - Adaptive Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Poor': 399940, 'Good': 396245, 'Fair': 387605})\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(random_state=42)\n",
    "X_ada, y_ada = ada.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# X_train_ada, X_test_ada, y_train_ada, y_test_ada = train_test_split(X_ada, y_ada, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.41523158668344895\n",
      "Accuracy Score, Test Set:  0.444408290562609\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 3997  9697 10413]\n",
      " [17588 64639 49855]\n",
      " [  840  2104  3751]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.17      0.17     24107\n",
      "        Good       0.85      0.49      0.62    132082\n",
      "        Poor       0.06      0.56      0.11      6695\n",
      "\n",
      "    accuracy                           0.44    162884\n",
      "   macro avg       0.36      0.41      0.30    162884\n",
      "weighted avg       0.71      0.44      0.53    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_ada, X_test, y_ada, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.41389266677366765\n",
      "Accuracy Score, Test Set:  0.5410230593551238\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 9252 12409  2446]\n",
      " [44857 77947  9278]\n",
      " [ 2436  3334   925]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.16      0.38      0.23     24107\n",
      "        Good       0.83      0.59      0.69    132082\n",
      "        Poor       0.07      0.14      0.10      6695\n",
      "\n",
      "    accuracy                           0.54    162884\n",
      "   macro avg       0.36      0.37      0.34    162884\n",
      "weighted avg       0.70      0.54      0.60    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_ada, X_test, y_ada, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5006301793392409\n",
      "Accuracy Score, Test Set: 0.44144299010338645\n",
      "Confusion Matrix: \n",
      " [[ 7087  8760  8260]\n",
      " [31630 61904 38548]\n",
      " [ 1811  1971  2913]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.29      0.22     24107\n",
      "        Good       0.85      0.47      0.60    132082\n",
      "        Poor       0.06      0.44      0.10      6695\n",
      "\n",
      "    accuracy                           0.44    162884\n",
      "   macro avg       0.36      0.40      0.31    162884\n",
      "weighted avg       0.72      0.44      0.53    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_ada, X_test, y_ada, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5006031475177185\n",
      "Accuracy Score, Test Set: 0.4452984946342182\n",
      "Confusion Matrix: \n",
      " [[ 6824  8983  8300]\n",
      " [30505 62750 38827]\n",
      " [ 1718  2019  2958]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.28      0.22     24107\n",
      "        Good       0.85      0.48      0.61    132082\n",
      "        Poor       0.06      0.44      0.10      6695\n",
      "\n",
      "    accuracy                           0.45    162884\n",
      "   macro avg       0.36      0.40      0.31    162884\n",
      "weighted avg       0.72      0.45      0.53    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_ada, X_test, y_ada, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.3654981035487713\n",
      "Accuracy Score, Test Set: 0.11891898529014513\n",
      "Confusion Matrix: \n",
      " [[  2043   1717  20347]\n",
      " [ 10956  11456 109670]\n",
      " [   393    431   5871]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.15      0.08      0.11     24107\n",
      "        Good       0.84      0.09      0.16    132082\n",
      "        Poor       0.04      0.88      0.08      6695\n",
      "\n",
      "    accuracy                           0.12    162884\n",
      "   macro avg       0.35      0.35      0.12    162884\n",
      "weighted avg       0.71      0.12      0.15    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_ada, X_test, y_ada, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4102484393346793\n",
      "Accuracy Score, Test Set: 0.44108690847474274\n",
      "Confusion Matrix: \n",
      " [[ 6313  8881  8913]\n",
      " [28892 62220 40970]\n",
      " [ 1359  2023  3313]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.26      0.21     24107\n",
      "        Good       0.85      0.47      0.61    132082\n",
      "        Poor       0.06      0.49      0.11      6695\n",
      "\n",
      "    accuracy                           0.44    162884\n",
      "   macro avg       0.36      0.41      0.31    162884\n",
      "weighted avg       0.72      0.44      0.53    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_ada, X_test, y_ada, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Over-sampling and Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Poor': 396226, 'Fair': 396145, 'Good': 396134})\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTETomek(random_state=42)\n",
    "X_smt, y_smt = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_smt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# X_train_smt, X_test_smt, y_train_smt, y_test_smt = train_test_split(X_smt, y_smt, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.424885044656943\n",
      "Accuracy Score, Test Set:  0.4710898553571867\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 5531 10022  8554]\n",
      " [22401 68038 41643]\n",
      " [ 1345  2186  3164]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.19      0.23      0.21     24107\n",
      "        Good       0.85      0.52      0.64    132082\n",
      "        Poor       0.06      0.47      0.11      6695\n",
      "\n",
      "    accuracy                           0.47    162884\n",
      "   macro avg       0.37      0.41      0.32    162884\n",
      "weighted avg       0.72      0.47      0.55    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_smt, X_test, y_smt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.4417112254470953\n",
      "Accuracy Score, Test Set:  0.4511185874610152\n",
      "\n",
      "Confusion Matrix: \n",
      " [[11136  9567  3404]\n",
      " [57817 61126 13139]\n",
      " [ 2981  2496  1218]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.15      0.46      0.23     24107\n",
      "        Good       0.84      0.46      0.60    132082\n",
      "        Poor       0.07      0.18      0.10      6695\n",
      "\n",
      "    accuracy                           0.45    162884\n",
      "   macro avg       0.35      0.37      0.31    162884\n",
      "weighted avg       0.70      0.45      0.52    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_smt, X_test, y_smt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5105413944409153\n",
      "Accuracy Score, Test Set: 0.4983792146558287\n",
      "Confusion Matrix: \n",
      " [[ 5991 10370  7746]\n",
      " [23796 72363 35923]\n",
      " [ 1534  2337  2824]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.19      0.25      0.22     24107\n",
      "        Good       0.85      0.55      0.67    132082\n",
      "        Poor       0.06      0.42      0.11      6695\n",
      "\n",
      "    accuracy                           0.50    162884\n",
      "   macro avg       0.37      0.41      0.33    162884\n",
      "weighted avg       0.72      0.50      0.58    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_smt, X_test, y_smt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.510518676825087\n",
      "Accuracy Score, Test Set: 0.503051251197171\n",
      "Confusion Matrix: \n",
      " [[ 5802 10545  7760]\n",
      " [22795 73308 35979]\n",
      " [ 1477  2389  2829]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.19      0.24      0.21     24107\n",
      "        Good       0.85      0.56      0.67    132082\n",
      "        Poor       0.06      0.42      0.11      6695\n",
      "\n",
      "    accuracy                           0.50    162884\n",
      "   macro avg       0.37      0.41      0.33    162884\n",
      "weighted avg       0.72      0.50      0.58    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_smt, X_test, y_smt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.37112591028224534\n",
      "Accuracy Score, Test Set: 0.15695832617077185\n",
      "Confusion Matrix: \n",
      " [[  2408   2248  19451]\n",
      " [ 10351  17509 104222]\n",
      " [   525    521   5649]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.10      0.13     24107\n",
      "        Good       0.86      0.13      0.23    132082\n",
      "        Poor       0.04      0.84      0.08      6695\n",
      "\n",
      "    accuracy                           0.16    162884\n",
      "   macro avg       0.36      0.36      0.15    162884\n",
      "weighted avg       0.73      0.16      0.21    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_smt, X_test, y_smt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4183305917938923\n",
      "Accuracy Score, Test Set: 0.5074838535399425\n",
      "Confusion Matrix: \n",
      " [[ 6949 10459  6699]\n",
      " [30941 73010 28131]\n",
      " [ 1519  2474  2702]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.29      0.22     24107\n",
      "        Good       0.85      0.55      0.67    132082\n",
      "        Poor       0.07      0.40      0.12      6695\n",
      "\n",
      "    accuracy                           0.51    162884\n",
      "   macro avg       0.37      0.41      0.34    162884\n",
      "weighted avg       0.72      0.51      0.58    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_smt, X_test, y_smt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Extensions - Borderline SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Good': 396245, 'Fair': 396245, 'Poor': 396245})\n"
     ]
    }
   ],
   "source": [
    "bsmt = BorderlineSMOTE(random_state=42)\n",
    "X_bsmt, y_bsmt = bsmt.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_bsmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt = train_test_split(X_bsmt, y_bsmt, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.4651709590446988\n",
      "Accuracy Score, Test Set:  0.5187863755801675\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 4632 11385  8090]\n",
      " [19686 76755 35641]\n",
      " [ 1040  2540  3115]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.19      0.19     24107\n",
      "        Good       0.85      0.58      0.69    132082\n",
      "        Poor       0.07      0.47      0.12      6695\n",
      "\n",
      "    accuracy                           0.52    162884\n",
      "   macro avg       0.37      0.41      0.33    162884\n",
      "weighted avg       0.72      0.52      0.59    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_bsmt, X_test, y_bsmt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.5120880599965509\n",
      "Accuracy Score, Test Set:  0.5333795830161342\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 9439 11769  2899]\n",
      " [44991 76375 10716]\n",
      " [ 2529  3101  1065]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.39      0.23     24107\n",
      "        Good       0.84      0.58      0.68    132082\n",
      "        Poor       0.07      0.16      0.10      6695\n",
      "\n",
      "    accuracy                           0.53    162884\n",
      "   macro avg       0.36      0.38      0.34    162884\n",
      "weighted avg       0.71      0.53      0.59    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_bsmt, X_test, y_bsmt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.6194711184578564\n",
      "Accuracy Score, Test Set: 0.4364087325949756\n",
      "Confusion Matrix: \n",
      " [[ 8589  8531  6987]\n",
      " [39808 59952 32322]\n",
      " [ 2205  1947  2543]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.36      0.23     24107\n",
      "        Good       0.85      0.45      0.59    132082\n",
      "        Poor       0.06      0.38      0.10      6695\n",
      "\n",
      "    accuracy                           0.44    162884\n",
      "   macro avg       0.36      0.40      0.31    162884\n",
      "weighted avg       0.72      0.44      0.52    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_bsmt, X_test, y_bsmt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.6194652298451715\n",
      "Accuracy Score, Test Set: 0.4409088676604209\n",
      "Confusion Matrix: \n",
      " [[ 8485  8693  6929]\n",
      " [39098 60798 32186]\n",
      " [ 2167  1994  2534]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.35      0.23     24107\n",
      "        Good       0.85      0.46      0.60    132082\n",
      "        Poor       0.06      0.38      0.10      6695\n",
      "\n",
      "    accuracy                           0.44    162884\n",
      "   macro avg       0.36      0.40      0.31    162884\n",
      "weighted avg       0.72      0.44      0.52    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_bsmt, X_test, y_bsmt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4091778234846286\n",
      "Accuracy Score, Test Set: 0.2671901475896957\n",
      "Confusion Matrix: \n",
      " [[ 2137  4713 17257]\n",
      " [ 9983 36127 85972]\n",
      " [  456   982  5257]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.09      0.12     24107\n",
      "        Good       0.86      0.27      0.42    132082\n",
      "        Poor       0.05      0.79      0.09      6695\n",
      "\n",
      "    accuracy                           0.27    162884\n",
      "   macro avg       0.36      0.38      0.21    162884\n",
      "weighted avg       0.73      0.27      0.36    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_bsmt, X_test, y_bsmt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4647520263136864\n",
      "Accuracy Score, Test Set: 0.5686746396208344\n",
      "Confusion Matrix: \n",
      " [[ 6453 12181  5473]\n",
      " [29629 83903 18550]\n",
      " [ 1405  3018  2272]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.27      0.21     24107\n",
      "        Good       0.85      0.64      0.73    132082\n",
      "        Poor       0.09      0.34      0.14      6695\n",
      "\n",
      "    accuracy                           0.57    162884\n",
      "   macro avg       0.37      0.41      0.36    162884\n",
      "weighted avg       0.72      0.57      0.63    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_bsmt, X_test, y_bsmt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM-SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Good': 396245, 'Fair': 396245, 'Poor': 396245})\n"
     ]
    }
   ],
   "source": [
    "svmsm = SVMSMOTE(random_state=42)\n",
    "X_svmsm, y_svmsm = svmsm.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_svmsm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# X_train_svmsm, X_test_svmsm, y_train_svmsm, y_test_svmsm = train_test_split(X_svmsm, y_svmsm, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.5867228608562884\n",
      "Accuracy Score, Test Set:  0.720960929250264\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  4934  17359   1814]\n",
      " [ 17179 111605   3298]\n",
      " [  1393   4408    894]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.21      0.20      0.21     24107\n",
      "        Good       0.84      0.84      0.84    132082\n",
      "        Poor       0.15      0.13      0.14      6695\n",
      "\n",
      "    accuracy                           0.72    162884\n",
      "   macro avg       0.40      0.39      0.40    162884\n",
      "weighted avg       0.72      0.72      0.72    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_svmsm, X_test, y_svmsm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.6602253656197554\n",
      "Accuracy Score, Test Set:  0.6128410402495027\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 7140 14528  2439]\n",
      " [31771 91649  8662]\n",
      " [ 1828  3834  1033]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.30      0.22     24107\n",
      "        Good       0.83      0.69      0.76    132082\n",
      "        Poor       0.09      0.15      0.11      6695\n",
      "\n",
      "    accuracy                           0.61    162884\n",
      "   macro avg       0.36      0.38      0.36    162884\n",
      "weighted avg       0.70      0.61      0.65    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_svmsm, X_test, y_svmsm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.7173137831392195\n",
      "Accuracy Score, Test Set: 0.6405969892684364\n",
      "Confusion Matrix: \n",
      " [[ 4383 14831  4893]\n",
      " [13744 97989 20349]\n",
      " [ 1230  3494  1971]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.23      0.18      0.20     24107\n",
      "        Good       0.84      0.74      0.79    132082\n",
      "        Poor       0.07      0.29      0.12      6695\n",
      "\n",
      "    accuracy                           0.64    162884\n",
      "   macro avg       0.38      0.41      0.37    162884\n",
      "weighted avg       0.72      0.64      0.67    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_svmsm, X_test, y_svmsm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.7173087357569181\n",
      "Accuracy Score, Test Set: 0.645367255224577\n",
      "Confusion Matrix: \n",
      " [[ 4158 15106  4843]\n",
      " [12784 98998 20300]\n",
      " [ 1162  3569  1964]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.23      0.17      0.20     24107\n",
      "        Good       0.84      0.75      0.79    132082\n",
      "        Poor       0.07      0.29      0.12      6695\n",
      "\n",
      "    accuracy                           0.65    162884\n",
      "   macro avg       0.38      0.41      0.37    162884\n",
      "weighted avg       0.72      0.65      0.68    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_svmsm, X_test, y_svmsm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.5074781174946477\n",
      "Accuracy Score, Test Set: 0.587117212249208\n",
      "Confusion Matrix: \n",
      " [[ 2710 14429  6968]\n",
      " [ 9700 90571 31811]\n",
      " [  745  3599  2351]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.21      0.11      0.15     24107\n",
      "        Good       0.83      0.69      0.75    132082\n",
      "        Poor       0.06      0.35      0.10      6695\n",
      "\n",
      "    accuracy                           0.59    162884\n",
      "   macro avg       0.37      0.38      0.33    162884\n",
      "weighted avg       0.71      0.59      0.64    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_svmsm, X_test, y_svmsm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.5874126697708068\n",
      "Accuracy Score, Test Set: 0.699663564254316\n",
      "Confusion Matrix: \n",
      " [[  6182  16464   1461]\n",
      " [ 22407 107017   2658]\n",
      " [  1576   4354    765]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.20      0.26      0.23     24107\n",
      "        Good       0.84      0.81      0.82    132082\n",
      "        Poor       0.16      0.11      0.13      6695\n",
      "\n",
      "    accuracy                           0.70    162884\n",
      "   macro avg       0.40      0.39      0.39    162884\n",
      "weighted avg       0.72      0.70      0.71    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_svmsm, X_test, y_svmsm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
