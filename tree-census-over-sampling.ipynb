{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Over Sampling Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (KFold, \n",
    "                                     cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (mean_squared_error,\n",
    "                             classification_report,\n",
    "                             mean_absolute_error,\n",
    "                             accuracy_score,\n",
    "                             confusion_matrix,\n",
    "                             average_precision_score,\n",
    "                             precision_recall_curve,\n",
    "                             recall_score,\n",
    "                             f1_score)\n",
    "\n",
    "from sklearn.metrics import plot_precision_recall_curve ## WORKS NOW TRY IT\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import (RandomOverSampler,\n",
    "                                    SMOTE,\n",
    "                                    ADASYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_l</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_l</th>\n",
       "      <th>root_grate_l</th>\n",
       "      <th>root_other_l</th>\n",
       "      <th>trunk_wire_l</th>\n",
       "      <th>trnk_light_l</th>\n",
       "      <th>trnk_other_l</th>\n",
       "      <th>...</th>\n",
       "      <th>OnCurb</th>\n",
       "      <th>Harmful</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_l  num_problems  tree_dbh  root_stone_l  root_grate_l  \\\n",
       "0   Fair         1             0         3             0             0   \n",
       "1   Fair         1             1        21             1             0   \n",
       "2   Good         2             0         3             0             0   \n",
       "3   Good         2             1        10             1             0   \n",
       "4   Good         2             1        21             1             0   \n",
       "\n",
       "   root_other_l  trunk_wire_l  trnk_light_l  trnk_other_l  ...  OnCurb  \\\n",
       "0             0             0             0             0  ...       1   \n",
       "1             0             0             0             0  ...       1   \n",
       "2             0             0             0             0  ...       1   \n",
       "3             0             0             0             0  ...       1   \n",
       "4             0             0             0             0  ...       1   \n",
       "\n",
       "   Harmful  Helpful  Unsure  Damage  Bronx  Brooklyn  Manhattan  Queens  \\\n",
       "0        0        0       0       0      0         0          0       1   \n",
       "1        0        0       0       1      0         0          0       1   \n",
       "2        0        0       0       1      0         1          0       0   \n",
       "3        0        0       0       1      0         1          0       0   \n",
       "4        0        0       0       1      0         1          0       0   \n",
       "\n",
       "   Staten Island  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target and Response Variable, Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health_l') # keep the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488651, 24) (488651,)\n",
      "(162884, 24) (162884,)\n"
     ]
    }
   ],
   "source": [
    "# create targe and response variable\n",
    "y = tree_ml['health'].values\n",
    "X = tree_ml.drop('health', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6814200311571903\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "dummy_clf.fit(X, y)\n",
    "dc_pred = dummy_clf.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.681100785069106\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_freq = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf_freq.fit(X, y)\n",
    "dc_pred_freq = dummy_clf_freq.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Over Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Fair': 528327, 'Good': 528327, 'Poor': 528327})\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_ros, y_ros, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.4181268323049292\n",
      "Accuracy Score, Test Set:  0.41764207083478444\n"
     ]
    }
   ],
   "source": [
    "logreg_rs = LogisticRegression().fit(X_train_rs, y_train_rs)\n",
    "y_pred_logreg_rs = logreg_rs.predict(X_test_rs)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg_rs.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set: ', logreg_rs.score(X_test_rs, y_test_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.17      0.24    132500\n",
      "        Good       0.41      0.55      0.47    131527\n",
      "        Poor       0.43      0.54      0.48    132219\n",
      "\n",
      "    accuracy                           0.42    396246\n",
      "   macro avg       0.41      0.42      0.40    396246\n",
      "weighted avg       0.41      0.42      0.39    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_logreg_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.45059243649762143\n",
      "Accuracy Score, Test Set:  0.4412435709130187\n"
     ]
    }
   ],
   "source": [
    "# using 6 neighbors\n",
    "knn_rs = KNeighborsClassifier(n_neighbors=6)\n",
    "knn_rs.fit(X_train_rs, y_train_rs)\n",
    "y_pred_knn_rs = knn_rs.predict(X_test_rs)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn_rs.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set: ', knn_rs.score(X_test_rs, y_test_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.48      0.44    132500\n",
      "        Good       0.43      0.39      0.41    131527\n",
      "        Poor       0.50      0.45      0.47    132219\n",
      "\n",
      "    accuracy                           0.44    396246\n",
      "   macro avg       0.44      0.44      0.44    396246\n",
      "weighted avg       0.44      0.44      0.44    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_knn_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5073813760005383\n",
      "Accuracy Score, Test Set: 0.4940945776108781\n"
     ]
    }
   ],
   "source": [
    "decision_tree_ros = DecisionTreeClassifier(random_state=42).fit(X_train_rs, y_train_rs)\n",
    "y_pred_decision_tree_ros = decision_tree_ros.predict(X_test_rs)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', decision_tree_ros.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set:', decision_tree_ros.score(X_test_rs, y_test_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.53      0.32      0.40    132500\n",
      "        Good       0.46      0.58      0.51    131527\n",
      "        Poor       0.52      0.58      0.55    132219\n",
      "\n",
      "    accuracy                           0.49    396246\n",
      "   macro avg       0.50      0.49      0.49    396246\n",
      "weighted avg       0.50      0.49      0.49    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_decision_tree_ros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5073645513928672\n",
      "Accuracy Score, Test Set: 0.49455893561070646\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train_rs, y_train_rs)\n",
    "y_pred_forest_rs = rf.predict(X_test_rs)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', rf.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set:', rf.score(X_test_rs, y_test_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.53      0.32      0.40    132500\n",
      "        Good       0.46      0.59      0.51    131527\n",
      "        Poor       0.52      0.58      0.55    132219\n",
      "\n",
      "    accuracy                           0.49    396246\n",
      "   macro avg       0.50      0.49      0.49    396246\n",
      "weighted avg       0.50      0.49      0.49    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_forest_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.39208654578186053\n",
      "Accuracy Score, Test Set: 0.391463888594459\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB().fit(X_train_rs, y_train_rs)\n",
    "y_pred_g = gaussian.predict(X_test_rs)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_rs, y_test_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.06      0.11    132500\n",
      "        Good       0.37      0.87      0.52    131527\n",
      "        Poor       0.47      0.25      0.33    132219\n",
      "\n",
      "    accuracy                           0.39    396246\n",
      "   macro avg       0.42      0.39      0.32    396246\n",
      "weighted avg       0.42      0.39      0.32    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.4157840056867174\n",
      "Accuracy Score, Test Set: 0.4148685412597225\n"
     ]
    }
   ],
   "source": [
    "categorical = CategoricalNB()\n",
    "categorical.fit(X_train_rs, y_train_rs)\n",
    "y_pred_cnb = categorical.predict(X_test_rs)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test_rs, y_test_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.27      0.32    132500\n",
      "        Good       0.40      0.62      0.48    131527\n",
      "        Poor       0.47      0.36      0.41    132219\n",
      "\n",
      "    accuracy                           0.41    396246\n",
      "   macro avg       0.42      0.42      0.40    396246\n",
      "weighted avg       0.42      0.41      0.40    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation for SMOTE is found here: https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Fair': 528327, 'Good': 528327, 'Poor': 528327})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_sm, y_sm = sm.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm, y_sm, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.4214404387857681\n",
      "Accuracy Score, Test Set:  0.4209935242248502\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train_sm, y_train_sm)\n",
    "y_pred_lr = logreg.predict(X_test_sm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_sm, y_train_sm))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_sm, y_test_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.18      0.25    132500\n",
      "        Good       0.42      0.52      0.46    131527\n",
      "        Poor       0.43      0.56      0.49    132219\n",
      "\n",
      "    accuracy                           0.42    396246\n",
      "   macro avg       0.42      0.42      0.40    396246\n",
      "weighted avg       0.42      0.42      0.40    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.4488923098924487\n",
      "Accuracy Score, Test Set:  0.43925743098983966\n"
     ]
    }
   ],
   "source": [
    "# using 6 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X_train_sm, y_train_sm)\n",
    "y_pred_knn = knn.predict(X_test_sm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train_sm, y_train_sm))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test_sm, y_test_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.50      0.45    132500\n",
      "        Good       0.44      0.37      0.40    131527\n",
      "        Poor       0.49      0.45      0.47    132219\n",
      "\n",
      "    accuracy                           0.44    396246\n",
      "   macro avg       0.44      0.44      0.44    396246\n",
      "weighted avg       0.44      0.44      0.44    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5036522017102214\n",
      "Accuracy Score, Test Set: 0.4879594999066237\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "dtree.fit(X_train_sm, y_train_sm)\n",
    "y_pred_dtree = dtree.predict(X_test_sm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', dtree.score(X_train_sm, y_train_sm))\n",
    "print('Accuracy Score, Test Set:', dtree.score(X_test_sm, y_test_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.51      0.32      0.40    132500\n",
      "        Good       0.45      0.56      0.50    131527\n",
      "        Poor       0.51      0.58      0.54    132219\n",
      "\n",
      "    accuracy                           0.49    396246\n",
      "   macro avg       0.49      0.49      0.48    396246\n",
      "weighted avg       0.49      0.49      0.48    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm, y_pred_dtree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5036387420240844\n",
      "Accuracy Score, Test Set: 0.4890875870040329\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_sm, y_train_sm)\n",
    "y_pred_rf = rf.predict(X_test_sm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', rf.score(X_train_sm, y_train_sm))\n",
    "print('Accuracy Score, Test Set:', rf.score(X_test_sm, y_test_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.52      0.32      0.39    132500\n",
      "        Good       0.46      0.57      0.51    131527\n",
      "        Poor       0.51      0.58      0.54    132219\n",
      "\n",
      "    accuracy                           0.49    396246\n",
      "   macro avg       0.49      0.49      0.48    396246\n",
      "weighted avg       0.49      0.49      0.48    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.370339899136477\n",
      "Accuracy Score, Test Set: 0.37038354961311915\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train_sm, y_train_sm)\n",
    "y_pred_gaussian = gaussian.predict(X_test_sm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_sm, y_train_sm))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_sm, y_test_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.09      0.15    132500\n",
      "        Good       0.51      0.13      0.20    131527\n",
      "        Poor       0.35      0.89      0.51    132219\n",
      "\n",
      "    accuracy                           0.37    396246\n",
      "   macro avg       0.42      0.37      0.29    396246\n",
      "weighted avg       0.42      0.37      0.29    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm, y_pred_gaussian))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.4184473410810652\n",
      "Accuracy Score, Test Set: 0.41731651549794824\n"
     ]
    }
   ],
   "source": [
    "categorical = CategoricalNB()\n",
    "categorical.fit(X_train_sm, y_train_sm)\n",
    "y_pred_cnb = categorical.predict(X_test_sm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train_sm, y_train_sm))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test_sm, y_test_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.28      0.33    132500\n",
      "        Good       0.40      0.56      0.47    131527\n",
      "        Poor       0.46      0.41      0.43    132219\n",
      "\n",
      "    accuracy                           0.42    396246\n",
      "   macro avg       0.42      0.42      0.41    396246\n",
      "weighted avg       0.42      0.42      0.41    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADASYN - Adaptive Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Poor': 535394, 'Good': 528327, 'Fair': 526527})\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(random_state=42)\n",
    "X_ada, y_ada = ada.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X_train_ada, X_test_ada, y_train_ada, y_test_ada = train_test_split(X_ada, y_ada, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.41042487293386526\n",
      "Accuracy Score, Test Set:  0.4095361226676594\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train_ada, y_train_ada)\n",
    "y_pred_lr = logreg.predict(X_test_ada)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_ada, y_train_ada))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_ada, y_test_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.13      0.19    132088\n",
      "        Good       0.40      0.53      0.46    131397\n",
      "        Poor       0.42      0.57      0.48    134077\n",
      "\n",
      "    accuracy                           0.41    397562\n",
      "   macro avg       0.40      0.41      0.38    397562\n",
      "weighted avg       0.40      0.41      0.38    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_ada, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.4271744616772562\n",
      "Accuracy Score, Test Set:  0.4178895367263471\n"
     ]
    }
   ],
   "source": [
    "# using 6 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X_train_ada, y_train_ada)\n",
    "y_pred_knn = knn.predict(X_test_ada)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train_ada, y_train_ada))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test_ada, y_test_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.47      0.42    132088\n",
      "        Good       0.41      0.37      0.39    131397\n",
      "        Poor       0.47      0.41      0.44    134077\n",
      "\n",
      "    accuracy                           0.42    397562\n",
      "   macro avg       0.42      0.42      0.42    397562\n",
      "weighted avg       0.42      0.42      0.42    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_ada, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.49205826177216805\n",
      "Accuracy Score, Test Set: 0.47872533089178543\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "dtree.fit(X_train_ada, y_train_ada)\n",
    "y_pred_dtree = dtree.predict(X_test_ada)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', dtree.score(X_train_ada, y_train_ada))\n",
    "print('Accuracy Score, Test Set:', dtree.score(X_test_ada, y_test_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.46      0.39      0.42    132088\n",
      "        Good       0.47      0.46      0.46    131397\n",
      "        Poor       0.50      0.59      0.54    134077\n",
      "\n",
      "    accuracy                           0.48    397562\n",
      "   macro avg       0.48      0.48      0.48    397562\n",
      "weighted avg       0.48      0.48      0.48    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_ada, y_pred_dtree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.4920448466738102\n",
      "Accuracy Score, Test Set: 0.48007606360768884\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_ada, y_train_ada)\n",
    "y_pred_rf = rf.predict(X_test_ada)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', rf.score(X_train_ada, y_train_ada))\n",
    "print('Accuracy Score, Test Set:', rf.score(X_test_ada, y_test_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.46      0.39      0.42    132088\n",
      "        Good       0.47      0.47      0.47    131397\n",
      "        Poor       0.50      0.59      0.54    134077\n",
      "\n",
      "    accuracy                           0.48    397562\n",
      "   macro avg       0.48      0.48      0.48    397562\n",
      "weighted avg       0.48      0.48      0.48    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_ada, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.3664409576367963\n",
      "Accuracy Score, Test Set: 0.3675200346109538\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train_ada, y_train_ada)\n",
    "y_pred_gaussian = gaussian.predict(X_test_ada)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_ada, y_train_ada))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_ada, y_test_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.11      0.17    132088\n",
      "        Good       0.49      0.09      0.15    131397\n",
      "        Poor       0.36      0.90      0.51    134077\n",
      "\n",
      "    accuracy                           0.37    397562\n",
      "   macro avg       0.41      0.36      0.28    397562\n",
      "weighted avg       0.41      0.37      0.28    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_ada, y_pred_gaussian))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.40931812731934475\n",
      "Accuracy Score, Test Set: 0.4105598623610908\n"
     ]
    }
   ],
   "source": [
    "categorical = CategoricalNB()\n",
    "categorical.fit(X_train_ada, y_train_ada)\n",
    "y_pred_cnb = categorical.predict(X_test_ada)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train_ada, y_train_ada))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test_ada, y_test_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.25      0.30    132088\n",
      "        Good       0.40      0.49      0.44    131397\n",
      "        Poor       0.43      0.49      0.46    134077\n",
      "\n",
      "    accuracy                           0.41    397562\n",
      "   macro avg       0.41      0.41      0.40    397562\n",
      "weighted avg       0.41      0.41      0.40    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_ada, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
