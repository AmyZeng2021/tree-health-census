{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (classification_report,\n",
    "                             confusion_matrix)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import (RandomOverSampler,\n",
    "                                    SMOTE,\n",
    "                                    ADASYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_l</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_l</th>\n",
       "      <th>root_grate_l</th>\n",
       "      <th>root_other_l</th>\n",
       "      <th>trunk_wire_l</th>\n",
       "      <th>trnk_light_l</th>\n",
       "      <th>trnk_other_l</th>\n",
       "      <th>...</th>\n",
       "      <th>OnCurb</th>\n",
       "      <th>Harmful</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_l  num_problems  tree_dbh  root_stone_l  root_grate_l  \\\n",
       "0   Fair         1             0         3             0             0   \n",
       "1   Fair         1             1        21             1             0   \n",
       "2   Good         2             0         3             0             0   \n",
       "3   Good         2             1        10             1             0   \n",
       "4   Good         2             1        21             1             0   \n",
       "\n",
       "   root_other_l  trunk_wire_l  trnk_light_l  trnk_other_l  ...  OnCurb  \\\n",
       "0             0             0             0             0  ...       1   \n",
       "1             0             0             0             0  ...       1   \n",
       "2             0             0             0             0  ...       1   \n",
       "3             0             0             0             0  ...       1   \n",
       "4             0             0             0             0  ...       1   \n",
       "\n",
       "   Harmful  Helpful  Unsure  Damage  Bronx  Brooklyn  Manhattan  Queens  \\\n",
       "0        0        0       0       0      0         0          0       1   \n",
       "1        0        0       0       1      0         0          0       1   \n",
       "2        0        0       0       1      0         1          0       0   \n",
       "3        0        0       0       1      0         1          0       0   \n",
       "4        0        0       0       1      0         1          0       0   \n",
       "\n",
       "   Staten Island  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target and Response Variable, Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health_l') # keep the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488651, 24) (488651,)\n",
      "(162884, 24) (162884,)\n"
     ]
    }
   ],
   "source": [
    "# create targe and response variable\n",
    "y = tree_ml['health'].values\n",
    "X = tree_ml.drop('health', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.681154504362774\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "dummy_clf.fit(X, y)\n",
    "dc_pred = dummy_clf.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6812957093632729\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_freq = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf_freq.fit(X, y)\n",
    "dc_pred_freq = dummy_clf_freq.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "\n",
    "def logreg(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    print('Logistic Regression \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))\n",
    "    print()\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier\n",
    "\n",
    "def knn(X_train, X_test, y_train, y_test):\n",
    "    # using 6 neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print('KNN Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set: ', knn.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set: ', knn.score(X_test, y_test))\n",
    "    print()\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classificatin report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "\n",
    "def decision_tree(X_train, X_test, y_train, y_test):\n",
    "    decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    \n",
    "    print('Decision Tree Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "\n",
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Random Forest Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', rf.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', rf.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian naive bayes\n",
    "\n",
    "def gaussian(X_train, X_test, y_train, y_test):\n",
    "    gaussian = GaussianNB().fit(X_train, y_train)\n",
    "    y_pred = gaussian.predict(X_test)\n",
    "    \n",
    "    print('Gaussian Naive Bayes \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical naive bayes\n",
    "\n",
    "def categorical_naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    categorical = CategoricalNB().fit(X_train, y_train)\n",
    "    y_pred = categorical.predict(X_test)\n",
    "    \n",
    "    print('Categorical Naive Bayes \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', categorical.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', categorical.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation - 5-fold - for later\n",
    "# cv_scores = cross_val_score(logreg, X, y, cv=5)\n",
    "# print('CV Scores: {}'.format(cv_scores))\n",
    "# print('Average 5-Fold CV Score: {}'.format(np.mean(cv_scores)))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Over Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Fair': 528327, 'Good': 528327, 'Poor': 528327})\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_ros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267984, 24) (1267984,)\n",
      "(316997, 24) (316997,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_ros, y_ros, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train_rs.shape, y_train_rs.shape)\n",
    "print(X_test_rs.shape, y_test_rs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.41830023091774027\n",
      "Accuracy Score, Test Set:  0.4176190941870112\n",
      "\n",
      "Confusion Matrix: \n",
      " [[18074 46390 41555]\n",
      " [14041 57824 33213]\n",
      " [13884 35530 56486]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.17      0.24    106019\n",
      "        Good       0.41      0.55      0.47    105078\n",
      "        Poor       0.43      0.53      0.48    105900\n",
      "\n",
      "    accuracy                           0.42    316997\n",
      "   macro avg       0.41      0.42      0.40    316997\n",
      "weighted avg       0.41      0.42      0.40    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.4503589950661838\n",
      "Accuracy Score, Test Set:  0.4417896699337849\n",
      "\n",
      "Confusion Matrix: \n",
      " [[51833 34680 19506]\n",
      " [41419 46632 17027]\n",
      " [35494 28825 41581]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.49      0.44    106019\n",
      "        Good       0.42      0.44      0.43    105078\n",
      "        Poor       0.53      0.39      0.45    105900\n",
      "\n",
      "    accuracy                           0.44    316997\n",
      "   macro avg       0.45      0.44      0.44    316997\n",
      "weighted avg       0.45      0.44      0.44    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5071767467097377\n",
      "Accuracy Score, Test Set: 0.4939005731915444\n",
      "Confusion Matrix: \n",
      " [[34284 41223 30512]\n",
      " [18217 61063 25798]\n",
      " [12706 31976 61218]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.53      0.32      0.40    106019\n",
      "        Good       0.45      0.58      0.51    105078\n",
      "        Poor       0.52      0.58      0.55    105900\n",
      "\n",
      "    accuracy                           0.49    316997\n",
      "   macro avg       0.50      0.49      0.49    316997\n",
      "weighted avg       0.50      0.49      0.49    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5071578190261076\n",
      "Accuracy Score, Test Set: 0.4944179282453777\n",
      "Confusion Matrix: \n",
      " [[33521 41769 30729]\n",
      " [17586 61741 25751]\n",
      " [12310 32123 61467]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.53      0.32      0.40    106019\n",
      "        Good       0.46      0.59      0.51    105078\n",
      "        Poor       0.52      0.58      0.55    105900\n",
      "\n",
      "    accuracy                           0.49    316997\n",
      "   macro avg       0.50      0.49      0.49    316997\n",
      "weighted avg       0.50      0.49      0.49    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.3922092076871632\n",
      "Accuracy Score, Test Set: 0.391041555598318\n",
      "Confusion Matrix: \n",
      " [[ 6304 79508 20207]\n",
      " [ 4669 91154  9255]\n",
      " [ 4744 74655 26501]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.06      0.10    106019\n",
      "        Good       0.37      0.87      0.52    105078\n",
      "        Poor       0.47      0.25      0.33    105900\n",
      "\n",
      "    accuracy                           0.39    316997\n",
      "   macro avg       0.42      0.39      0.32    316997\n",
      "weighted avg       0.42      0.39      0.32    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.41472841928604776\n",
      "Accuracy Score, Test Set: 0.41291557964270953\n",
      "Confusion Matrix: \n",
      " [[28257 51549 26213]\n",
      " [23322 65130 16626]\n",
      " [21064 47330 37506]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.27      0.32    106019\n",
      "        Good       0.40      0.62      0.48    105078\n",
      "        Poor       0.47      0.35      0.40    105900\n",
      "\n",
      "    accuracy                           0.41    316997\n",
      "   macro avg       0.42      0.41      0.40    316997\n",
      "weighted avg       0.42      0.41      0.40    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Fair': 528327, 'Good': 528327, 'Poor': 528327})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_sm, y_sm = sm.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_sm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267984, 24) (1267984,)\n",
      "(316997, 24) (316997,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm, y_sm, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train_sm.shape, y_train_sm.shape)\n",
    "print(X_test_sm.shape, y_test_sm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.4217253530012997\n",
      "Accuracy Score, Test Set:  0.42248349353463915\n",
      "\n",
      "Confusion Matrix: \n",
      " [[20114 43859 42046]\n",
      " [15354 55234 34490]\n",
      " [13928 33394 58578]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.19      0.26    106019\n",
      "        Good       0.42      0.53      0.47    105078\n",
      "        Poor       0.43      0.55      0.49    105900\n",
      "\n",
      "    accuracy                           0.42    316997\n",
      "   macro avg       0.42      0.42      0.40    316997\n",
      "weighted avg       0.42      0.42      0.40    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.4516342477507603\n",
      "Accuracy Score, Test Set:  0.4430357385085663\n",
      "\n",
      "Confusion Matrix: \n",
      " [[50908 30993 24118]\n",
      " [40445 43899 20734]\n",
      " [34417 25849 45634]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.48      0.44    106019\n",
      "        Good       0.44      0.42      0.43    105078\n",
      "        Poor       0.50      0.43      0.46    105900\n",
      "\n",
      "    accuracy                           0.44    316997\n",
      "   macro avg       0.45      0.44      0.44    316997\n",
      "weighted avg       0.45      0.44      0.44    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5033588751908541\n",
      "Accuracy Score, Test Set: 0.487537736950192\n",
      "Confusion Matrix: \n",
      " [[34261 39794 31964]\n",
      " [19344 59333 26401]\n",
      " [13316 31630 60954]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.51      0.32      0.40    106019\n",
      "        Good       0.45      0.56      0.50    105078\n",
      "        Poor       0.51      0.58      0.54    105900\n",
      "\n",
      "    accuracy                           0.49    316997\n",
      "   macro avg       0.49      0.49      0.48    316997\n",
      "weighted avg       0.49      0.49      0.48    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5033462567351008\n",
      "Accuracy Score, Test Set: 0.48894784493228644\n",
      "Confusion Matrix: \n",
      " [[33611 39631 32777]\n",
      " [18553 59607 26918]\n",
      " [13029 31094 61777]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.52      0.32      0.39    106019\n",
      "        Good       0.46      0.57      0.51    105078\n",
      "        Poor       0.51      0.58      0.54    105900\n",
      "\n",
      "    accuracy                           0.49    316997\n",
      "   macro avg       0.49      0.49      0.48    316997\n",
      "weighted avg       0.49      0.49      0.48    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.37098575376345444\n",
      "Accuracy Score, Test Set: 0.37140099117657266\n",
      "Confusion Matrix: \n",
      " [[ 9529  8301 88189]\n",
      " [ 8284 13681 83113]\n",
      " [ 6373  5004 94523]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.09      0.15    106019\n",
      "        Good       0.51      0.13      0.21    105078\n",
      "        Poor       0.36      0.89      0.51    105900\n",
      "\n",
      "    accuracy                           0.37    316997\n",
      "   macro avg       0.42      0.37      0.29    316997\n",
      "weighted avg       0.42      0.37      0.29    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4184358793170892\n",
      "Accuracy Score, Test Set: 0.41775474215844316\n",
      "Confusion Matrix: \n",
      " [[30257 46426 29336]\n",
      " [24319 58847 21912]\n",
      " [21942 40635 43323]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.29      0.33    106019\n",
      "        Good       0.40      0.56      0.47    105078\n",
      "        Poor       0.46      0.41      0.43    105900\n",
      "\n",
      "    accuracy                           0.42    316997\n",
      "   macro avg       0.42      0.42      0.41    316997\n",
      "weighted avg       0.42      0.42      0.41    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADASYN - Adaptive Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Poor': 535394, 'Good': 528327, 'Fair': 526527})\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(random_state=42)\n",
    "X_ada, y_ada = ada.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_ada)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1192686, 24) (1192686,)\n",
      "(397562, 24) (397562,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_ada, X_test_ada, y_train_ada, y_test_ada = train_test_split(X_ada, y_ada, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_ada.shape, y_train_ada.shape)\n",
    "print(X_test_ada.shape, y_test_ada.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.41042487293386526\n",
      "Accuracy Score, Test Set:  0.4095361226676594\n",
      "\n",
      "Confusion Matrix: \n",
      " [[16721 57816 57551]\n",
      " [13874 69591 47932]\n",
      " [12083 45490 76504]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.13      0.19    132088\n",
      "        Good       0.40      0.53      0.46    131397\n",
      "        Poor       0.42      0.57      0.48    134077\n",
      "\n",
      "    accuracy                           0.41    397562\n",
      "   macro avg       0.40      0.41      0.38    397562\n",
      "weighted avg       0.40      0.41      0.38    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.42628990362928715\n",
      "Accuracy Score, Test Set:  0.4170594775154567\n",
      "\n",
      "Confusion Matrix: \n",
      " [[61171 43143 27774]\n",
      " [52315 54215 24867]\n",
      " [47435 36221 50421]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.46      0.42    132088\n",
      "        Good       0.41      0.41      0.41    131397\n",
      "        Poor       0.49      0.38      0.43    134077\n",
      "\n",
      "    accuracy                           0.42    397562\n",
      "   macro avg       0.43      0.42      0.42    397562\n",
      "weighted avg       0.43      0.42      0.42    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.49205826177216805\n",
      "Accuracy Score, Test Set: 0.47872533089178543\n",
      "Confusion Matrix: \n",
      " [[51913 38710 41465]\n",
      " [34711 59967 36719]\n",
      " [26119 29515 78443]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.46      0.39      0.42    132088\n",
      "        Good       0.47      0.46      0.46    131397\n",
      "        Poor       0.50      0.59      0.54    134077\n",
      "\n",
      "    accuracy                           0.48    397562\n",
      "   macro avg       0.48      0.48      0.48    397562\n",
      "weighted avg       0.48      0.48      0.48    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.4920448466738102\n",
      "Accuracy Score, Test Set: 0.48007606360768884\n",
      "Confusion Matrix: \n",
      " [[51080 39420 41588]\n",
      " [33648 61100 36649]\n",
      " [25768 29629 78680]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.46      0.39      0.42    132088\n",
      "        Good       0.47      0.47      0.47    131397\n",
      "        Poor       0.50      0.59      0.54    134077\n",
      "\n",
      "    accuracy                           0.48    397562\n",
      "   macro avg       0.48      0.48      0.48    397562\n",
      "weighted avg       0.48      0.48      0.48    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.3664409576367963\n",
      "Accuracy Score, Test Set: 0.3675200346109538\n",
      "Confusion Matrix: \n",
      " [[ 14056   7154 110878]\n",
      " [ 14328  11597 105472]\n",
      " [  8844   4774 120459]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.11      0.17    132088\n",
      "        Good       0.49      0.09      0.15    131397\n",
      "        Poor       0.36      0.90      0.51    134077\n",
      "\n",
      "    accuracy                           0.37    397562\n",
      "   macro avg       0.41      0.36      0.28    397562\n",
      "weighted avg       0.41      0.37      0.28    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.40931812731934475\n",
      "Accuracy Score, Test Set: 0.4105598623610908\n",
      "Confusion Matrix: \n",
      " [[32808 52308 46972]\n",
      " [27107 64274 40016]\n",
      " [25192 42744 66141]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.25      0.30    132088\n",
      "        Good       0.40      0.49      0.44    131397\n",
      "        Poor       0.43      0.49      0.46    134077\n",
      "\n",
      "    accuracy                           0.41    397562\n",
      "   macro avg       0.41      0.41      0.40    397562\n",
      "weighted avg       0.41      0.41      0.40    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Over-sampling and Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Poor': 528308, 'Fair': 528226, 'Good': 528213})\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTETomek(random_state=42)\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_smt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267797, 24) (1267797,)\n",
      "(316950, 24) (316950,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_smt, X_test_smt, y_train_smt, y_test_smt = train_test_split(X_smt, y_smt, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train_smt.shape, y_train_smt.shape)\n",
    "print(X_test_smt.shape, y_test_smt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.4197059939406703\n",
      "Accuracy Score, Test Set:  0.4183498974601672\n",
      "\n",
      "Confusion Matrix: \n",
      " [[19058 44960 42043]\n",
      " [14390 55919 34807]\n",
      " [13711 34443 57619]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.18      0.25    106061\n",
      "        Good       0.41      0.53      0.47    105116\n",
      "        Poor       0.43      0.54      0.48    105773\n",
      "\n",
      "    accuracy                           0.42    316950\n",
      "   macro avg       0.42      0.42      0.40    316950\n",
      "weighted avg       0.42      0.42      0.40    316950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_smt, X_test_smt, y_train_smt, y_test_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.44689252301433113\n",
      "Accuracy Score, Test Set:  0.43645054424988167\n",
      "\n",
      "Confusion Matrix: \n",
      " [[49599 32498 23964]\n",
      " [39594 43996 21526]\n",
      " [33289 27746 44738]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.47      0.43    106061\n",
      "        Good       0.42      0.42      0.42    105116\n",
      "        Poor       0.50      0.42      0.46    105773\n",
      "\n",
      "    accuracy                           0.44    316950\n",
      "   macro avg       0.44      0.44      0.44    316950\n",
      "weighted avg       0.44      0.44      0.44    316950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_smt, X_test_smt, y_train_smt, y_test_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5032627463229523\n",
      "Accuracy Score, Test Set: 0.48803912289004575\n",
      "Confusion Matrix: \n",
      " [[33688 40133 32240]\n",
      " [18746 59809 26561]\n",
      " [13098 31488 61187]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.51      0.32      0.39    106061\n",
      "        Good       0.46      0.57      0.51    105116\n",
      "        Poor       0.51      0.58      0.54    105773\n",
      "\n",
      "    accuracy                           0.49    316950\n",
      "   macro avg       0.49      0.49      0.48    316950\n",
      "weighted avg       0.49      0.49      0.48    316950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_smt, X_test_smt, y_train_smt, y_test_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5032517035455992\n",
      "Accuracy Score, Test Set: 0.4897333964347689\n",
      "Confusion Matrix: \n",
      " [[33297 40520 32244]\n",
      " [18070 60660 26386]\n",
      " [12876 31633 61264]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.52      0.31      0.39    106061\n",
      "        Good       0.46      0.58      0.51    105116\n",
      "        Poor       0.51      0.58      0.54    105773\n",
      "\n",
      "    accuracy                           0.49    316950\n",
      "   macro avg       0.50      0.49      0.48    316950\n",
      "weighted avg       0.50      0.49      0.48    316950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_smt, X_test_smt, y_train_smt, y_test_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.37264167686151645\n",
      "Accuracy Score, Test Set: 0.3717053162959457\n",
      "Confusion Matrix: \n",
      " [[ 9818  9001 87242]\n",
      " [ 8765 14567 81784]\n",
      " [ 6683  5663 93427]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.09      0.15    106061\n",
      "        Good       0.50      0.14      0.22    105116\n",
      "        Poor       0.36      0.88      0.51    105773\n",
      "\n",
      "    accuracy                           0.37    316950\n",
      "   macro avg       0.41      0.37      0.29    316950\n",
      "weighted avg       0.41      0.37      0.29    316950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_smt, X_test_smt, y_train_smt, y_test_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.41895035246179\n",
      "Accuracy Score, Test Set: 0.41653257611610667\n",
      "Confusion Matrix: \n",
      " [[30076 46742 29243]\n",
      " [24587 59060 21469]\n",
      " [22142 40747 42884]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.28      0.33    106061\n",
      "        Good       0.40      0.56      0.47    105116\n",
      "        Poor       0.46      0.41      0.43    105773\n",
      "\n",
      "    accuracy                           0.42    316950\n",
      "   macro avg       0.42      0.42      0.41    316950\n",
      "weighted avg       0.42      0.42      0.41    316950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_train_smt, X_test_smt, y_train_smt, y_test_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Extensions - Borderline SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Fair': 528327, 'Good': 528327, 'Poor': 528327})\n"
     ]
    }
   ],
   "source": [
    "bsmt = BorderlineSMOTE(random_state=42)\n",
    "X_bsmt, y_bsmt = bsmt.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_bsmt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267984, 24) (1267984,)\n",
      "(316997, 24) (316997,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt = train_test_split(X_bsmt, y_bsmt, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train_bsmt.shape, y_train_bsmt.shape)\n",
    "print(X_test_bsmt.shape, y_test_bsmt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.4732007659402642\n",
      "Accuracy Score, Test Set:  0.47196030246343024\n",
      "\n",
      "Confusion Matrix: \n",
      " [[19335 53031 33653]\n",
      " [14761 67937 22380]\n",
      " [15051 28511 62338]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.18      0.25    106019\n",
      "        Good       0.45      0.65      0.53    105078\n",
      "        Poor       0.53      0.59      0.56    105900\n",
      "\n",
      "    accuracy                           0.47    316997\n",
      "   macro avg       0.46      0.47      0.45    316997\n",
      "weighted avg       0.46      0.47      0.45    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.5668541558884024\n",
      "Accuracy Score, Test Set:  0.5580210538270078\n",
      "\n",
      "Confusion Matrix: \n",
      " [[53594 32055 20370]\n",
      " [36165 52324 16589]\n",
      " [19724 15203 70973]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.49      0.51      0.50    106019\n",
      "        Good       0.53      0.50      0.51    105078\n",
      "        Poor       0.66      0.67      0.66    105900\n",
      "\n",
      "    accuracy                           0.56    316997\n",
      "   macro avg       0.56      0.56      0.56    316997\n",
      "weighted avg       0.56      0.56      0.56    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.627391986018751\n",
      "Accuracy Score, Test Set: 0.6139774193446625\n",
      "Confusion Matrix: \n",
      " [[53056 22910 30053]\n",
      " [31660 49408 24010]\n",
      " [ 8214  5521 92165]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.57      0.50      0.53    106019\n",
      "        Good       0.63      0.47      0.54    105078\n",
      "        Poor       0.63      0.87      0.73    105900\n",
      "\n",
      "    accuracy                           0.61    316997\n",
      "   macro avg       0.61      0.61      0.60    316997\n",
      "weighted avg       0.61      0.61      0.60    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.6273817335234514\n",
      "Accuracy Score, Test Set: 0.6151004583639593\n",
      "Confusion Matrix: \n",
      " [[52565 23291 30163]\n",
      " [31005 50126 23947]\n",
      " [ 8091  5515 92294]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.57      0.50      0.53    106019\n",
      "        Good       0.64      0.48      0.54    105078\n",
      "        Poor       0.63      0.87      0.73    105900\n",
      "\n",
      "    accuracy                           0.62    316997\n",
      "   macro avg       0.61      0.61      0.60    316997\n",
      "weighted avg       0.61      0.62      0.60    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4458045211926964\n",
      "Accuracy Score, Test Set: 0.44354362975043926\n",
      "Confusion Matrix: \n",
      " [[12467 59414 34138]\n",
      " [10998 74866 19214]\n",
      " [ 8980 43651 53269]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.12      0.18    106019\n",
      "        Good       0.42      0.71      0.53    105078\n",
      "        Poor       0.50      0.50      0.50    105900\n",
      "\n",
      "    accuracy                           0.44    316997\n",
      "   macro avg       0.43      0.44      0.40    316997\n",
      "weighted avg       0.43      0.44      0.40    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4596099004403841\n",
      "Accuracy Score, Test Set: 0.457256693281009\n",
      "Confusion Matrix: \n",
      " [[25643 56319 24057]\n",
      " [21084 72390 11604]\n",
      " [19045 39939 46916]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.24      0.30    106019\n",
      "        Good       0.43      0.69      0.53    105078\n",
      "        Poor       0.57      0.44      0.50    105900\n",
      "\n",
      "    accuracy                           0.46    316997\n",
      "   macro avg       0.46      0.46      0.44    316997\n",
      "weighted avg       0.46      0.46      0.44    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_naive_bayes(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
