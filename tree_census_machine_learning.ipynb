{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Overview - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using random forest, decision trees, logistic regression, and SVC to model our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# from sklearn.metrics import plot_precision_recall_curve ## does not work?\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Categorical Naive Bayes\n",
    "# from sklearn.naive_bayes import CategoricalNB\n",
    "## that one doesn't load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unbalanced data set - handle this in the machine learning\n",
    "## Oversampling or undersampling or random sampling\n",
    "\n",
    "## Statistical analysis is not for target variables\n",
    "\n",
    "## Stratified sampling - happens during machine learning\n",
    "## Python has lots of APIs to apply stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_labels</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_labels</th>\n",
       "      <th>root_grate_labels</th>\n",
       "      <th>root_other_labels</th>\n",
       "      <th>trunk_wire_labels</th>\n",
       "      <th>trnk_light_labels</th>\n",
       "      <th>trnk_other_labels</th>\n",
       "      <th>...</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>None.1</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>NoDamage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_labels  num_problems  tree_dbh  root_stone_labels  \\\n",
       "0   Fair              1             0         3                  0   \n",
       "1   Fair              1             1        21                  1   \n",
       "2   Good              2             0         3                  0   \n",
       "3   Good              2             1        10                  1   \n",
       "4   Good              2             1        21                  1   \n",
       "\n",
       "   root_grate_labels  root_other_labels  trunk_wire_labels  trnk_light_labels  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   trnk_other_labels  ...  Helpful  None.1  Unsure  Damage  NoDamage  Bronx  \\\n",
       "0                  0  ...        0       1       0       0         1      0   \n",
       "1                  0  ...        0       1       0       1         0      0   \n",
       "2                  0  ...        0       1       0       1         0      0   \n",
       "3                  0  ...        0       1       0       1         0      0   \n",
       "4                  0  ...        0       1       0       1         0      0   \n",
       "\n",
       "   Brooklyn  Manhattan  Queens  Staten Island  \n",
       "0         0          0       1              0  \n",
       "1         0          0       1              0  \n",
       "2         1          0       0              0  \n",
       "3         1          0       0              0  \n",
       "4         1          0       0              0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape\n",
    "\n",
    "# take a subsample and run experiment, then run on entire dataset\n",
    "# knn and svc takes a long time - try a smaller set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure model performance - does this look okay?\n",
    "\n",
    "def cross_validate(model, nfolds, feats, targets):\n",
    "    score = -1 * (cross_val_score(model, feats, targets, cv=nfolds, scoring='neg_mean_absolute_error'))\n",
    "    return np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target and Response Variable, Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health') # keep the numerical health column: health_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521228, 28) (521228,)\n",
      "(130307, 28) (130307,)\n"
     ]
    }
   ],
   "source": [
    "# create targe and response variable\n",
    "y = tree_ml['health_labels'].values\n",
    "X = tree_ml.drop('health_labels', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=23456789, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by using the DummyClassifier to make predictions using simple rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6804991289800241\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "dummy_clf.fit(X, y)\n",
    "dc_pred = dummy_clf.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6801369074570054\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_freq = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf_freq.fit(X, y)\n",
    "dc_pred_freq = dummy_clf_freq.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.8106605938284206\n",
      "Accuracy Score, Test Set:  0.8109925023214409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar scores, no overfitting\n",
    "# look into precision and recall\n",
    "\n",
    "# need to know how the model performs for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.00      0.00      5356\n",
      "           1       0.37      0.02      0.04     19285\n",
      "           2       0.81      1.00      0.90    105666\n",
      "\n",
      "    accuracy                           0.81    130307\n",
      "   macro avg       0.55      0.34      0.31    130307\n",
      "weighted avg       0.73      0.81      0.73    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80919674 0.8115297  0.81120738 0.81205921 0.80682542]\n",
      "Average 5-Fold CV Score: 0.8101636903619912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "\n",
    "cv_scores = cross_val_score(logreg, X, y, cv=5)\n",
    "\n",
    "print(cv_scores)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Score:  0.2283396131156333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# mean absolute error\n",
    "\n",
    "print(\"MAE Score: \", cross_validate(logreg, 10, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[     5    264   5087]\n",
      " [     4    366  18915]\n",
      " [     2    357 105307]]\n"
     ]
    }
   ],
   "source": [
    "# model performance - confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix: \\n\", cm) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8109925023214409\n"
     ]
    }
   ],
   "source": [
    "# model performance - accuracy score\n",
    "\n",
    "print (\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision score - error message\n",
    "\n",
    "# average_precision = average_precision_score(y_test, y_pred)\n",
    "\n",
    "# print('Average precision-recall score: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7981305685803526\n"
     ]
    }
   ],
   "source": [
    "# response and target variables are X and y, respectively\n",
    "# split with train_test_split\n",
    "\n",
    "# create KNN with 7 neighbbors\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# fit to training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# accuracy scoring\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7974475661322876\n"
     ]
    }
   ],
   "source": [
    "# could increasing the number of neighbors increase accuracy scores?\n",
    "\n",
    "# create KNN with 7 neighbbors\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "# fit to training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# accuracy scoring\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80529058300782\n"
     ]
    }
   ],
   "source": [
    "# increase to 15!\n",
    "\n",
    "# create KNN with 7 neighbbors\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "# fit to training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy scoring\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [0.79946588 0.79934309 0.8065645  0.80951138 0.79018779]\n",
      "Average 5-Fold CV Score: 0.8010145272318449\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "cv_scores_knn = cross_val_score(knn, X, y, cv=5)\n",
    "\n",
    "print('CV scores: ', cv_scores_knn)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_knn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute error - this one takes too long to run so skip for now\n",
    "\n",
    "# print(\"MAE Score: \", cross_validate(knn, 10, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[   156    359   4841]\n",
      " [   159    833  18293]\n",
      " [   155   1565 103946]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_knn = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix: \\n\", cm_knn) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.03      0.05      5356\n",
      "           1       0.30      0.04      0.08     19285\n",
      "           2       0.82      0.98      0.89    105666\n",
      "\n",
      "    accuracy                           0.81    130307\n",
      "   macro avg       0.48      0.35      0.34    130307\n",
      "weighted avg       0.72      0.81      0.74    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79946588 0.79934309 0.8065645  0.80951138 0.79018779]\n",
      "Average 5-Fold CV Score: 0.8010145272318449\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "\n",
    "cv_scores_knn = cross_val_score(knn, X, y, cv=5)\n",
    "\n",
    "print(cv_scores_knn)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_knn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8052905830078199"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score - micro\n",
    "\n",
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34078335924573483"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score - macro\n",
    "\n",
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05355304, 0.07558298, 0.89321406])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score - None\n",
    "\n",
    "f1_score(y_test, y_pred, average=None) ## what does this mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8003100370663127\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print(decision_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8252089296814445\n",
      "Accuracy Score, Test Set: 0.8003100370663127\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8003100370663127"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall score\n",
    "recall_score(y_test, y_pred_decision_tree, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04219567, 0.05781696, 0.97424905])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_decision_tree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8003100370663128"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_decision_tree, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06951707, 0.09718893, 0.89065481])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_decision_tree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[   226    376   4754]\n",
      " [   368   1115  17802]\n",
      " [   552   2169 102945]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_decision_tree = confusion_matrix(y_test, y_pred_decision_tree)\n",
    "print (\"Confusion Matrix: \\n\", cm_decision_tree) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.04      0.07      5356\n",
      "           1       0.30      0.06      0.10     19285\n",
      "           2       0.82      0.97      0.89    105666\n",
      "\n",
      "    accuracy                           0.80    130307\n",
      "   macro avg       0.44      0.36      0.35    130307\n",
      "weighted avg       0.72      0.80      0.74    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [0.78996524 0.80413178 0.80542104 0.80261997 0.77589846]\n",
      "Average 5-Fold CV Score: 0.7956072966149171\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "\n",
    "cv_scores_dtc = cross_val_score(decision_tree, X, y, cv=5)\n",
    "\n",
    "print('CV scores: ', cv_scores_dtc)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_dtc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "y_pred_forest = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8047917609951882\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print('Accuracy:',metrics.accuracy_score(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[   188    326   4842]\n",
      " [   232    931  18122]\n",
      " [   294   1621 103751]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_forest = confusion_matrix(y_test, y_pred_forest)\n",
    "print ('Confusion Matrix: \\n', cm_forest) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.04      0.06      5356\n",
      "           1       0.32      0.05      0.08     19285\n",
      "           2       0.82      0.98      0.89    105666\n",
      "\n",
      "    accuracy                           0.80    130307\n",
      "   macro avg       0.47      0.36      0.35    130307\n",
      "weighted avg       0.72      0.80      0.74    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79741687 0.80746238 0.80807631 0.80618079 0.78578281]\n",
      "Average 5-Fold CV Score: 0.8009838304926058\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "\n",
    "cv_scores_forest = cross_val_score(forest, X, y, cv=5)\n",
    "\n",
    "print(cv_scores_forest)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_forest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulli = BernoulliNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred_bernoulli = bernoulli.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8038248137091637\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test, y_pred_bernoulli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[    63    481   4812]\n",
      " [    57   1096  18132]\n",
      " [    69   2012 103585]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_bernoulli = confusion_matrix(y_test, y_pred_bernoulli)\n",
    "print ('Confusion Matrix: \\n', cm_bernoulli) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.01      0.02      5356\n",
      "           1       0.31      0.06      0.10     19285\n",
      "           2       0.82      0.98      0.89    105666\n",
      "\n",
      "    accuracy                           0.80    130307\n",
      "   macro avg       0.49      0.35      0.34    130307\n",
      "weighted avg       0.72      0.80      0.74    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_bernoulli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8038248137091637"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall score\n",
    "\n",
    "recall_score(y_test, y_pred_bernoulli, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79946588 0.79934309 0.8065645  0.80951138 0.79018779]\n",
      "Average 5-Fold CV Score: 0.8010145272318449\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "\n",
    "cv_scores_bernoulli = cross_val_score(knn, X, y, cv=5)\n",
    "\n",
    "print(cv_scores_bernoulli)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_bernoulli)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine - SVM - takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SVM classifier\n",
    "svm_svc = svm.SVC(gamma='auto')\n",
    "\n",
    "# train the data\n",
    "svm_svc.fit(X_train, y_train)\n",
    "\n",
    "# predict results using test data\n",
    "y_pred = svm_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision score\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# recall score\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
