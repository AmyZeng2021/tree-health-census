{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Overview - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using random forest, decision trees, logistic regression, and SVC to model our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (KFold, \n",
    "                                     cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (mean_squared_error,\n",
    "                             classification_report,\n",
    "                             mean_absolute_error,\n",
    "                             accuracy_score,\n",
    "                             confusion_matrix,\n",
    "                             average_precision_score,\n",
    "                             precision_recall_curve,\n",
    "                             recall_score,\n",
    "                             f1_score)\n",
    "\n",
    "from sklearn.metrics import plot_precision_recall_curve # OPTIONAL\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import (RandomUnderSampler, \n",
    "                                     ClusterCentroids,\n",
    "                                     TomekLinks,\n",
    "                                     NeighbourhoodCleaningRule,\n",
    "                                     NearMiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_l</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_l</th>\n",
       "      <th>root_grate_l</th>\n",
       "      <th>root_other_l</th>\n",
       "      <th>trunk_wire_l</th>\n",
       "      <th>trnk_light_l</th>\n",
       "      <th>trnk_other_l</th>\n",
       "      <th>...</th>\n",
       "      <th>OnCurb</th>\n",
       "      <th>Harmful</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_l  num_problems  tree_dbh  root_stone_l  root_grate_l  \\\n",
       "0   Fair         1             0         3             0             0   \n",
       "1   Fair         1             1        21             1             0   \n",
       "2   Good         2             0         3             0             0   \n",
       "3   Good         2             1        10             1             0   \n",
       "4   Good         2             1        21             1             0   \n",
       "\n",
       "   root_other_l  trunk_wire_l  trnk_light_l  trnk_other_l  ...  OnCurb  \\\n",
       "0             0             0             0             0  ...       1   \n",
       "1             0             0             0             0  ...       1   \n",
       "2             0             0             0             0  ...       1   \n",
       "3             0             0             0             0  ...       1   \n",
       "4             0             0             0             0  ...       1   \n",
       "\n",
       "   Harmful  Helpful  Unsure  Damage  Bronx  Brooklyn  Manhattan  Queens  \\\n",
       "0        0        0       0       0      0         0          0       1   \n",
       "1        0        0       0       1      0         0          0       1   \n",
       "2        0        0       0       1      0         1          0       0   \n",
       "3        0        0       0       1      0         1          0       0   \n",
       "4        0        0       0       1      0         1          0       0   \n",
       "\n",
       "   Staten Island  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target and Response Variable, Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health_l') # keep the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488651, 24) (488651,)\n",
      "(162884, 24) (162884,)\n"
     ]
    }
   ],
   "source": [
    "# create targe and response variable\n",
    "y = tree_ml['health'].values\n",
    "X = tree_ml.drop('health', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by using the DummyClassifier to make predictions using simple rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6812251068630235\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "dummy_clf.fit(X, y)\n",
    "dc_pred = dummy_clf.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6811775269172032\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_freq = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf_freq.fit(X, y)\n",
    "dc_pred_freq = dummy_clf_freq.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.8106685548581708\n",
      "Accuracy Score, Test Set:  0.8109697698975958\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "\n",
    "cv_scores = cross_val_score(logreg, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80927348 0.8115297  0.81109994 0.81189038 0.80661054]\n",
      "Average 5-Fold CV Score: 0.8100808091660465\n"
     ]
    }
   ],
   "source": [
    "print(cv_scores)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[   425  23678      4]\n",
      " [   416 131664      2]\n",
      " [   320   6370      5]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_logreg)\n",
    "print (\"Confusion Matrix: \\n\", cm) ## why is the matrix 3x3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add labels, calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.37      0.02      0.03     24107\n",
      "        Good       0.81      1.00      0.90    132082\n",
      "        Poor       0.45      0.00      0.00      6695\n",
      "\n",
      "    accuracy                           0.81    162884\n",
      "   macro avg       0.54      0.34      0.31    162884\n",
      "weighted avg       0.73      0.81      0.73    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7819736745168341\n"
     ]
    }
   ],
   "source": [
    "# start with 15 due to large dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# fit to training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy scoring\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.7936605061690245\n",
      "Accuracy Score, Test Set:  0.7819736745168341\n"
     ]
    }
   ],
   "source": [
    "# accuracy scoring\n",
    "\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None, param_grid={'n_neighbors': [3, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use GridSearch\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':[3, 10]}\n",
    "\n",
    "gridsearch = GridSearchCV(knn, parameters)\n",
    "\n",
    "# fit to data\n",
    "gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [0.77301296 0.79154612 0.78173851 0.78559095 0.75418051]\n",
      "Average 5-Fold CV Score: 0.7772138104629835\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "cv_scores_knn = cross_val_score(knn, X, y, cv=5)\n",
    "\n",
    "print('CV scores: ', cv_scores_knn)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_knn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  2348  21581    178]\n",
      " [  7046 124869    167]\n",
      " [   843   5698    154]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_knn = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix: \\n\", cm_knn) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.23      0.10      0.14     24107\n",
      "        Good       0.82      0.95      0.88    132082\n",
      "        Poor       0.31      0.02      0.04      6695\n",
      "\n",
      "    accuracy                           0.78    162884\n",
      "   macro avg       0.45      0.36      0.35    162884\n",
      "weighted avg       0.71      0.78      0.73    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8255912706614741\n",
      "Accuracy Score, Test Set: 0.8010547383413963\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [0.79194518 0.80511408 0.80618846 0.80332599 0.77837722]\n",
      "Average 5-Fold CV Score: 0.7969901847176284\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "\n",
    "cv_scores_dtc = cross_val_score(decision_tree, X, y, cv=5)\n",
    "\n",
    "print('CV scores: ', cv_scores_dtc)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_dtc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  1478  22367    262]\n",
      " [  2918 128799    365]\n",
      " [   516   5977    202]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_decision_tree = confusion_matrix(y_test, y_pred_decision_tree)\n",
    "print (\"Confusion Matrix: \\n\", cm_decision_tree) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.30      0.06      0.10     24107\n",
      "        Good       0.82      0.98      0.89    132082\n",
      "        Poor       0.24      0.03      0.05      6695\n",
      "\n",
      "    accuracy                           0.80    162884\n",
      "   macro avg       0.45      0.36      0.35    162884\n",
      "weighted avg       0.72      0.80      0.74    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_decision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "y_pred_forest = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8255851313104854\n",
      "Accuracy Score, Test Set: 0.8046769480120822\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do GridSearch for optimal parameters\n",
    "## training and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79773919 0.80779237 0.80796887 0.80640334 0.78619721]\n",
      "Average 5-Fold CV Score: 0.8012201953847453\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "\n",
    "cv_scores_forest = cross_val_score(forest, X, y, cv=5)\n",
    "\n",
    "print(cv_scores_forest)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_forest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[   526  23452    129]\n",
      " [  2899 128499    684]\n",
      " [   137   6527     31]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm_forest = confusion_matrix(y_test, y_pred_forest)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm_forest) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.32      0.05      0.08     24107\n",
      "        Good       0.82      0.98      0.89    132082\n",
      "        Poor       0.26      0.03      0.06      6695\n",
      "\n",
      "    accuracy                           0.80    162884\n",
      "   macro avg       0.47      0.35      0.34    162884\n",
      "weighted avg       0.72      0.80      0.74    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = GaussianNB().fit(X_train, y_train)\n",
    "y_pred_gaussian = gaussian.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7394096412170624\n",
      "Accuracy Score, Training Set: 0.7382139809393616\n",
      "Accuracy Score, Test Set: 0.7394096412170624\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77301296 0.79154612 0.78173851 0.78559095 0.75418051]\n",
      "Average 5-Fold CV Score: 0.7772138104629835\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "\n",
    "cv_scores_gaussian = cross_val_score(gaussian, X, y, cv=5)\n",
    "\n",
    "print(cv_scores_gaussian)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_gaussian)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  2822  18304   2981]\n",
      " [  9371 116416   6295]\n",
      " [   663   4832   1200]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_gaussian = confusion_matrix(y_test, y_pred_gaussian)\n",
    "print ('Confusion Matrix: \\n', cm_gaussian) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.22      0.12      0.15     24107\n",
      "        Good       0.83      0.88      0.86    132082\n",
      "        Poor       0.11      0.18      0.14      6695\n",
      "\n",
      "    accuracy                           0.74    162884\n",
      "   macro avg       0.39      0.39      0.38    162884\n",
      "weighted avg       0.71      0.74      0.72    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_gaussian))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "categorical = CategoricalNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred_cate = categorical.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800901254880774\n",
      "Accuracy Score, Training Set: 0.8006921095014642\n",
      "Accuracy Score, Test Set: 0.800901254880774\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  1536  22310    261]\n",
      " [  3115 128696    271]\n",
      " [   584   5889    222]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_categorical = confusion_matrix(y_test, y_pred_cate)\n",
    "print ('Confusion Matrix: \\n', cm_categorical) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.29      0.06      0.10     24107\n",
      "        Good       0.82      0.97      0.89    132082\n",
      "        Poor       0.29      0.03      0.06      6695\n",
      "\n",
      "    accuracy                           0.80    162884\n",
      "   macro avg       0.47      0.36      0.35    162884\n",
      "weighted avg       0.72      0.80      0.74    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_cate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the precision and recall scores are highly accurate for good trees but extremely off-the-mark for fair and poor trees, we need to look into under-sampling and over-sampling techniques in order to increase the accuracies rates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
