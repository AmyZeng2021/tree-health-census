{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Overview - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using random forest, decision trees, logistic regression, and SVC to model our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (KFold, \n",
    "                                     cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (mean_squared_error,\n",
    "                             classification_report,\n",
    "                             mean_absolute_error,\n",
    "                             accuracy_score,\n",
    "                             confusion_matrix,\n",
    "                             average_precision_score,\n",
    "                             precision_recall_curve,\n",
    "                             recall_score,\n",
    "                             f1_score)\n",
    "\n",
    "from sklearn.metrics import plot_precision_recall_curve ## WORKS NOW TRY IT\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import (RandomUnderSampler, \n",
    "                                     ClusterCentroids,\n",
    "                                     TomekLinks,\n",
    "                                     NeighbourhoodCleaningRule,\n",
    "                                     NearMiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_labels</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_labels</th>\n",
       "      <th>root_grate_labels</th>\n",
       "      <th>root_other_labels</th>\n",
       "      <th>trunk_wire_labels</th>\n",
       "      <th>trnk_light_labels</th>\n",
       "      <th>trnk_other_labels</th>\n",
       "      <th>...</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>None.1</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>NoDamage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_labels  num_problems  tree_dbh  root_stone_labels  \\\n",
       "0   Fair              1             0         3                  0   \n",
       "1   Fair              1             1        21                  1   \n",
       "2   Good              2             0         3                  0   \n",
       "3   Good              2             1        10                  1   \n",
       "4   Good              2             1        21                  1   \n",
       "\n",
       "   root_grate_labels  root_other_labels  trunk_wire_labels  trnk_light_labels  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   trnk_other_labels  ...  Helpful  None.1  Unsure  Damage  NoDamage  Bronx  \\\n",
       "0                  0  ...        0       1       0       0         1      0   \n",
       "1                  0  ...        0       1       0       1         0      0   \n",
       "2                  0  ...        0       1       0       1         0      0   \n",
       "3                  0  ...        0       1       0       1         0      0   \n",
       "4                  0  ...        0       1       0       1         0      0   \n",
       "\n",
       "   Brooklyn  Manhattan  Queens  Staten Island  \n",
       "0         0          0       1              0  \n",
       "1         0          0       1              0  \n",
       "2         1          0       0              0  \n",
       "3         1          0       0              0  \n",
       "4         1          0       0              0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target and Response Variable, Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health_labels') # keep the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488651, 28) (488651,)\n",
      "(162884, 28) (162884,)\n"
     ]
    }
   ],
   "source": [
    "# create targe and response variable\n",
    "y = tree_ml['health'].values\n",
    "X = tree_ml.drop('health', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=23456789, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by using the DummyClassifier to make predictions using simple rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6806311249587512\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "dummy_clf.fit(X, y)\n",
    "dc_pred = dummy_clf.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6812957093632729\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_freq = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf_freq.fit(X, y)\n",
    "dc_pred_freq = dummy_clf_freq.predict(X)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.8106685548581708\n",
      "Accuracy Score, Test Set:  0.8110250239434199\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rebalance data - results consistently horrible\n",
    "\n",
    "## oversampling or undersampling to obtain better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "\n",
    "cv_scores = cross_val_score(logreg, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80918907 0.81161411 0.81119971 0.81205921 0.80682542]\n",
      "Average 5-Fold CV Score: 0.8101775038946488\n"
     ]
    }
   ],
   "source": [
    "print(cv_scores)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[   413  23688      6]\n",
      " [   395 131682      5]\n",
      " [   297   6390      8]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_logreg)\n",
    "print (\"Confusion Matrix: \\n\", cm) ## why is the matrix 3x3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add labels, calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.37      0.02      0.03     24107\n",
      "        Good       0.81      1.00      0.90    132082\n",
      "        Poor       0.42      0.00      0.00      6695\n",
      "\n",
      "    accuracy                           0.81    162884\n",
      "   macro avg       0.54      0.34      0.31    162884\n",
      "weighted avg       0.73      0.81      0.73    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8089867635863559\n"
     ]
    }
   ],
   "source": [
    "# start with 15 due to large dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "# fit to training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy scoring\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.8131713636112481\n",
      "Accuracy Score, Test Set:  0.8089867635863559\n"
     ]
    }
   ],
   "source": [
    "# accuracy scoring\n",
    "\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [10, 20]}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use GridSearch\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':[10, 20]}\n",
    "\n",
    "gridsearch = GridSearchCV(knn, parameters)\n",
    "\n",
    "# fit to data\n",
    "gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_n_neighbors',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(gridsearch.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_n_neighbors',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(gridsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [0.77355783 0.79189913 0.78118597 0.78547584 0.75378145]\n",
      "Average 5-Fold CV Score: 0.7771800440498208\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "cv_scores_knn = cross_val_score(knn, X, y, cv=5)\n",
    "\n",
    "print('CV scores: ', cv_scores_knn)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_knn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[   822  23178    107]\n",
      " [  1173 130810     99]\n",
      " [   375   6181    139]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_knn = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix: \\n\", cm_knn) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.35      0.03      0.06     24107\n",
      "        Good       0.82      0.99      0.90    132082\n",
      "        Poor       0.40      0.02      0.04      6695\n",
      "\n",
      "    accuracy                           0.81    162884\n",
      "   macro avg       0.52      0.35      0.33    162884\n",
      "weighted avg       0.73      0.81      0.74    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8255912706614741\n",
      "Accuracy Score, Test Set: 0.8010915743719457\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores:  [0.79180704 0.80516012 0.80606568 0.80344878 0.77818536]\n",
      "Average 5-Fold CV Score: 0.7969333957500364\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "\n",
    "cv_scores_dtc = cross_val_score(decision_tree, X, y, cv=5)\n",
    "\n",
    "print('CV scores: ', cv_scores_dtc)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_dtc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  1471  22368    268]\n",
      " [  2915 128806    361]\n",
      " [   508   5979    208]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_decision_tree = confusion_matrix(y_test, y_pred_decision_tree)\n",
    "print (\"Confusion Matrix: \\n\", cm_decision_tree) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.30      0.06      0.10     24107\n",
      "        Good       0.82      0.98      0.89    132082\n",
      "        Poor       0.25      0.03      0.06      6695\n",
      "\n",
      "    accuracy                           0.80    162884\n",
      "   macro avg       0.46      0.36      0.35    162884\n",
      "weighted avg       0.72      0.80      0.74    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_decision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "y_pred_forest = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.825587177760815\n",
      "Accuracy Score, Test Set: 0.804572579258859\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do GridSearch for optimal parameters\n",
    "## training and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79809987 0.80739331 0.80815305 0.80663357 0.78623558]\n",
      "Average 5-Fold CV Score: 0.8013030765806901\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "\n",
    "cv_scores_forest = cross_val_score(forest, X, y, cv=5)\n",
    "\n",
    "print(cv_scores_forest)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_forest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  1123  22698    286]\n",
      " [  1990 129700    392]\n",
      " [   426   6040    229]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm_forest = confusion_matrix(y_test, y_pred_forest)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm_forest) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.32      0.05      0.08     24107\n",
      "        Good       0.82      0.98      0.89    132082\n",
      "        Poor       0.25      0.03      0.06      6695\n",
      "\n",
      "    accuracy                           0.80    162884\n",
      "   macro avg       0.46      0.35      0.34    162884\n",
      "weighted avg       0.72      0.80      0.74    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred_gaussian = gaussian.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7370828319540287\n",
      "Accuracy Score, Training Set: 0.7358298663053999\n",
      "Accuracy Score, Test Set: 0.7370828319540287\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "print('Accuracy:',metrics.accuracy_score(y_test, y_pred_gaussian))\n",
    "\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77355783 0.79189913 0.78118597 0.78547584 0.75378145]\n",
      "Average 5-Fold CV Score: 0.7771800440498208\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "\n",
    "cv_scores_gaussian = cross_val_score(knn, X, y, cv=5)\n",
    "\n",
    "print(cv_scores_gaussian)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_gaussian)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  2780  18251   3076]\n",
      " [  9399 116048   6635]\n",
      " [   661   4803   1231]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_gaussian = confusion_matrix(y_test, y_pred_gaussian)\n",
    "print ('Confusion Matrix: \\n', cm_gaussian) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.22      0.12      0.15     24107\n",
      "        Good       0.83      0.88      0.86    132082\n",
      "        Poor       0.11      0.18      0.14      6695\n",
      "\n",
      "    accuracy                           0.74    162884\n",
      "   macro avg       0.39      0.39      0.38    162884\n",
      "weighted avg       0.71      0.74      0.72    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_gaussian))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "categorical = CategoricalNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred_cate = categorical.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8007047960511775\n",
      "Accuracy Score, Training Set: 0.8005058825214724\n",
      "Accuracy Score, Test Set: 0.8007047960511775\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_pred_cate))\n",
    "\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  1550  22290    267]\n",
      " [  3153 128633    296]\n",
      " [   567   5889    239]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cm_categorical = confusion_matrix(y_test, y_pred_cate)\n",
    "print ('Confusion Matrix: \\n', cm_categorical) ## why is the matrix 9x9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.29      0.06      0.11     24107\n",
      "        Good       0.82      0.97      0.89    132082\n",
      "        Poor       0.30      0.04      0.06      6695\n",
      "\n",
      "    accuracy                           0.80    162884\n",
      "   macro avg       0.47      0.36      0.35    162884\n",
      "weighted avg       0.72      0.80      0.74    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_cate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the precision and recall scores are highly accurate for good trees but extremely off-the-mark for fair and poor trees, we need to look into under-sampling and over-sampling techniques in order to increase the accuracies rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Data: Over and Under Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_under = RandomUnderSampler(random_state=42)\n",
    "X_rs, y_rs = random_under.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random undersampling Counter({'Fair': 26781, 'Good': 26781, 'Poor': 26781})\n"
     ]
    }
   ],
   "source": [
    "print('Random undersampling {}'.format(Counter(y_rs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_rs, y_rs, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg_rs = LogisticRegression().fit(X_train_rs, y_train_rs)\n",
    "\n",
    "y_pred_logreg_rs = logreg_rs.predict(X_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.17      0.24      6648\n",
      "        Good       0.42      0.53      0.47      6744\n",
      "        Poor       0.42      0.53      0.47      6694\n",
      "\n",
      "    accuracy                           0.41     20086\n",
      "   macro avg       0.41      0.41      0.39     20086\n",
      "weighted avg       0.41      0.41      0.39     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_logreg_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less than half of all three groups are correctly placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3976401473663248\n"
     ]
    }
   ],
   "source": [
    "# create KNN with 15 neighbbors\n",
    "knn_rs = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "# fit to training data\n",
    "knn_rs.fit(X_train_rs, y_train_rs)\n",
    "\n",
    "# predict\n",
    "y_pred_knn_rs = knn_rs.predict(X_test_rs)\n",
    "\n",
    "# accuracy scoring\n",
    "print(knn_rs.score(X_test_rs, y_test_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.35      0.38      0.37      6648\n",
      "        Good       0.42      0.41      0.41      6744\n",
      "        Poor       0.42      0.41      0.41      6694\n",
      "\n",
      "    accuracy                           0.40     20086\n",
      "   macro avg       0.40      0.40      0.40     20086\n",
      "weighted avg       0.40      0.40      0.40     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_knn_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_rs = DecisionTreeClassifier(random_state=42).fit(X_train_rs, y_train_rs)\n",
    "\n",
    "y_pred_decision_tree_rs = decision_tree_rs.predict(X_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40022901523449167\n",
      "Accuracy Score, Training Set: 0.543107024909969\n",
      "Accuracy Score, Test Set: 0.40022901523449167\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "print(decision_tree_rs.score(X_test_rs, y_test_rs))\n",
    "print('Accuracy Score, Training Set:', decision_tree_rs.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set:', decision_tree_rs.score(X_test_rs, y_test_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.37      0.31      0.33      6648\n",
      "        Good       0.40      0.50      0.45      6744\n",
      "        Poor       0.43      0.39      0.41      6694\n",
      "\n",
      "    accuracy                           0.40     20086\n",
      "   macro avg       0.40      0.40      0.40     20086\n",
      "weighted avg       0.40      0.40      0.40     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_decision_tree_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClusterCentroids -  this one takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster = ClusterCentroids(random_state=42)\n",
    "# X_rs, y_rs = cluster.fit_sample(X, y)\n",
    "# print('Cluster centriods undersampling {}'.format(Counter(y_rs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TomekLinks undersampling Counter({'Good': 527601, 'Fair': 95768, 'Poor': 26781})\n"
     ]
    }
   ],
   "source": [
    "tomek = TomekLinks()\n",
    "X_rs, y_rs = tomek.fit_sample(X, y)\n",
    "print('TomekLinks undersampling {}'.format(Counter(y_rs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_rs, y_rs, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "\n",
    "logreg_rs = LogisticRegression().fit(X_train_rs, y_train_rs)\n",
    "\n",
    "y_pred_logreg_rs = logreg_rs.predict(X_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.34      0.02      0.03     23788\n",
      "        Good       0.81      1.00      0.90    131921\n",
      "        Poor       0.64      0.00      0.00      6829\n",
      "\n",
      "    accuracy                           0.81    162538\n",
      "   macro avg       0.60      0.34      0.31    162538\n",
      "weighted avg       0.74      0.81      0.73    162538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_logreg_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "\n",
    "decision_tree_rs = DecisionTreeClassifier(random_state=42).fit(X_train_rs, y_train_rs)\n",
    "\n",
    "y_pred_decision_tree_rs = decision_tree_rs.predict(X_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.29      0.06      0.10     23788\n",
      "        Good       0.82      0.98      0.89    131921\n",
      "        Poor       0.25      0.03      0.06      6829\n",
      "\n",
      "    accuracy                           0.80    162538\n",
      "   macro avg       0.46      0.36      0.35    162538\n",
      "weighted avg       0.72      0.80      0.74    162538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_decision_tree_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian naive bayes\n",
    "\n",
    "gaussian_rs = GaussianNB().fit(X_train_rs, y_train_rs)\n",
    "\n",
    "y_pred_gaussian_rs = gaussian_rs.predict(X_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.7341041647867567\n",
      "Accuracy Score, Test Set: 0.7328932311213378\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "print('Accuracy Score, Training Set:', gaussian_rs.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set:', gaussian_rs.score(X_test_rs, y_test_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.20      0.11      0.15     23788\n",
      "        Good       0.83      0.87      0.85    131921\n",
      "        Poor       0.12      0.19      0.15      6829\n",
      "\n",
      "    accuracy                           0.73    162538\n",
      "   macro avg       0.38      0.39      0.38    162538\n",
      "weighted avg       0.71      0.73      0.72    162538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_gaussian_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_sample(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
