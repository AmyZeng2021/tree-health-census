{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Overview - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of building our machine learning model is to correctly predict a tree's health based on independent variables. We are classifying categorical variables. They are nominal, meaning that they do not have any intrinsic order to them, unlike ordinal variables. To measure our model's success, we are relying on a [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), which shows the main classification metrics such as precision, recall, and f1-score.\n",
    "\n",
    "Our algorithms of choice are: [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), and [Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes). To prepare our data, we separate our target variable, y or tree health, from the independent variables, X. Next, we split X and y into training and test sets by a percentage. In our case, we are training with 75% of our data and testing with the remaining 25% percent. After splitting, we are ready to begin testing.\n",
    "\n",
    "It's important to note that due to the heavily imbalanced group representation of our data, we are incorporating under sampling and over sampling methods in an effort to improve our precision and recall scores to find the best possible model. There are two separate notebooks for under and over sampling techniques due to the number of methods used and the length of the notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (StratifiedKFold, cross_val_score, GridSearchCV, train_test_split)\n",
    "from sklearn.metrics import (classification_report, confusion_matrix)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# under sampling\n",
    "import imblearn\n",
    "from imblearn.under_sampling import (RandomUnderSampler, EditedNearestNeighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_l</th>\n",
       "      <th>root_grate_l</th>\n",
       "      <th>root_other_l</th>\n",
       "      <th>trunk_wire_l</th>\n",
       "      <th>trnk_light_l</th>\n",
       "      <th>trnk_other_l</th>\n",
       "      <th>brch_light_l</th>\n",
       "      <th>...</th>\n",
       "      <th>OnCurb</th>\n",
       "      <th>Harmful</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  num_problems  tree_dbh  root_stone_l  root_grate_l  root_other_l  \\\n",
       "0   Fair             0         3             0             0             0   \n",
       "1   Fair             1        21             1             0             0   \n",
       "2   Good             0         3             0             0             0   \n",
       "3   Good             1        10             1             0             0   \n",
       "4   Good             1        21             1             0             0   \n",
       "\n",
       "   trunk_wire_l  trnk_light_l  trnk_other_l  brch_light_l  ...  OnCurb  \\\n",
       "0             0             0             0             0  ...       1   \n",
       "1             0             0             0             0  ...       1   \n",
       "2             0             0             0             0  ...       1   \n",
       "3             0             0             0             0  ...       1   \n",
       "4             0             0             0             0  ...       1   \n",
       "\n",
       "   Harmful  Helpful  Unsure  Damage  Bronx  Brooklyn  Manhattan  Queens  \\\n",
       "0        0        0       0       0      0         0          0       1   \n",
       "1        0        0       0       1      0         0          0       1   \n",
       "2        0        0       0       1      0         1          0       0   \n",
       "3        0        0       0       1      0         1          0       0   \n",
       "4        0        0       0       1      0         1          0       0   \n",
       "\n",
       "   Staten Island  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with splitting our data into training and testing sets in a stratified fashion so that our resulting sets have the same proportions of classes as our originals. 75% of our data is used to train the models while the remaining 25% is used for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456074, 24) (456074,)\n",
      "(195461, 24) (195461,)\n"
     ]
    }
   ],
   "source": [
    "y = tree['health'].values # target variable\n",
    "X = tree.drop('health', axis=1).values # feature variables\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.810708349960752\n",
      "Accuracy Score, Test Set:  0.8108062477936775\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.36      0.02      0.04     28928\n",
      "        Good       0.81      1.00      0.90    158499\n",
      "        Poor       0.40      0.00      0.00      8034\n",
      "\n",
      "    accuracy                           0.81    195461\n",
      "   macro avg       0.52      0.34      0.31    195461\n",
      "weighted avg       0.73      0.81      0.73    195461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed: 23.2min remaining: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 31.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 15}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [4,15]}\n",
    "\n",
    "clf = GridSearchCV(knn, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "clf.fit(X, y).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.8125348079478331\n",
      "Accuracy Score, Test Set:  0.8088877064989947\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.36      0.04      0.08     28928\n",
      "        Good       0.82      0.99      0.90    158499\n",
      "        Poor       0.42      0.02      0.04      8034\n",
      "\n",
      "    accuracy                           0.81    195461\n",
      "   macro avg       0.53      0.35      0.34    195461\n",
      "weighted avg       0.73      0.81      0.74    195461\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy scoring\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test, knn_pred)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8259317566886075\n",
      "Accuracy Score, Test Set: 0.8012647024214549\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.30      0.06      0.10     28928\n",
      "        Good       0.82      0.98      0.89    158499\n",
      "        Poor       0.25      0.03      0.06      8034\n",
      "\n",
      "    accuracy                           0.80    195461\n",
      "   macro avg       0.46      0.36      0.35    195461\n",
      "weighted avg       0.72      0.80      0.74    195461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "decision_tree_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test, decision_tree_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8259273714353372\n",
      "Accuracy Score, Test Set: 0.8053678227370166\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.33      0.05      0.08     28928\n",
      "        Good       0.82      0.98      0.89    158499\n",
      "        Poor       0.27      0.04      0.07      8034\n",
      "\n",
      "    accuracy                           0.81    195461\n",
      "   macro avg       0.47      0.36      0.35    195461\n",
      "weighted avg       0.72      0.81      0.74    195461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.7371084516986278\n",
      "Accuracy Score, Test Set: 0.7380091169082323\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.21      0.11      0.14     28928\n",
      "        Good       0.83      0.88      0.86    158499\n",
      "        Poor       0.12      0.19      0.15      8034\n",
      "\n",
      "    accuracy                           0.74    195461\n",
      "   macro avg       0.39      0.39      0.38    195461\n",
      "weighted avg       0.71      0.74      0.72    195461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "gaussian_pred = gaussian.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, gaussian_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though accuracy scores are relatively high for our models, they consistently under predict the number of fair and poor trees. Good trees are the vast majority so our next step is to selectively remove those trees until they are about equal in amount to fair and poor trees. By under sampling, we balance the classes so that machine learning models can learn to correctly identify each type of tree. We are using edited nearest neighbors for our under sampling method, which edits the samples based on the edited nearest neighbor method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Under Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The under sampling method we are using is edited nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Good': 312229, 'Poor': 26781, 'Fair': 1553})\n",
      "(238394, 24) (238394,)\n",
      "(102169, 24) (102169,)\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "enn = EditedNearestNeighbours()\n",
    "X_enn, y_enn = enn.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_enn)))\n",
    "\n",
    "# train test split\n",
    "X_train_enn, X_test_enn, y_train_enn, y_test_enn = train_test_split(X_enn, y_enn, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train_enn.shape, y_train_enn.shape)\n",
    "print(X_test_enn.shape, y_test_enn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.9209040495985638\n",
      "Accuracy Score, Test Set:  0.921825602677916\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.08      0.00      0.00       462\n",
      "        Good       0.93      1.00      0.96     93715\n",
      "        Poor       0.64      0.10      0.17      7992\n",
      "\n",
      "    accuracy                           0.92    102169\n",
      "   macro avg       0.55      0.37      0.38    102169\n",
      "weighted avg       0.90      0.92      0.89    102169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train_enn, y_train_enn)\n",
    "logreg_pred = logreg.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_enn, logreg_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.9459382367005881\n",
      "Accuracy Score, Test Set:  0.9449050103260285\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.61      0.44      0.51       462\n",
      "        Good       0.95      1.00      0.97     93715\n",
      "        Poor       0.85      0.38      0.53      7992\n",
      "\n",
      "    accuracy                           0.94    102169\n",
      "   macro avg       0.80      0.61      0.67    102169\n",
      "weighted avg       0.94      0.94      0.94    102169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X_train_enn, y_train_enn)\n",
    "knn_pred = knn.predict(X_test_enn)\n",
    "\n",
    "# accuracy scoring\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_enn, knn_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.9653179190751445\n",
      "Accuracy Score, Test Set: 0.9557889379361646\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.69      0.85      0.76       462\n",
      "        Good       0.96      1.00      0.98     93715\n",
      "        Poor       0.91      0.49      0.64      7992\n",
      "\n",
      "    accuracy                           0.96    102169\n",
      "   macro avg       0.85      0.78      0.79    102169\n",
      "weighted avg       0.95      0.96      0.95    102169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_enn, y_train_enn)\n",
    "decision_tree_pred = decision_tree.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_enn, decision_tree_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has very high accuracy scores for both training and test sets. It has a high precision rate for good and poor trees and strong recall scores for fair and good trees. The two top performing models both have lower scores for classifying fair trees. Since the accuracy scores are already in the mid-90s, the amount of hyper parameter tuning that we can do is minimal. Thus, to evaluate the model's performance, we are using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.95560319 0.95494252 0.95580873 0.95551445 0.95607235]\n",
      "Average 5-Fold Scores: 0.9555882477259795\n"
     ]
    }
   ],
   "source": [
    "# stratified KFold\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "\n",
    "# cross validation\n",
    "tree_score = cross_val_score(decision_tree, X_enn, y_enn, cv=kf)\n",
    "\n",
    "print('Scores: ', tree_score)\n",
    "print(\"Average 5-Fold Scores: {}\".format(np.mean(tree_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.9653179190751445\n",
      "Accuracy Score, Test Set: 0.9571298534780609\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.77      0.84      0.80       462\n",
      "        Good       0.96      1.00      0.98     93715\n",
      "        Poor       0.94      0.49      0.64      7992\n",
      "\n",
      "    accuracy                           0.96    102169\n",
      "   macro avg       0.89      0.78      0.81    102169\n",
      "weighted avg       0.96      0.96      0.95    102169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=42)\n",
    "forest.fit(X_train_enn, y_train_enn)\n",
    "forest_pred = forest.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_enn, forest_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has high precision scores overall and strong recall scores for good and fair trees. Since precision and recall have an inverse relationship, we are aiming for high precision scores. The overall accuracy score is at 95% and the difference between the training and test set scores is less than 1%, so our model is not grossly over fitted.\n",
    "\n",
    "To evaluate this model, we are using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.95761455 0.9567043  0.95752646 0.95768734 0.95773138]\n",
      "Average 5-Fold Scores: 0.9574528075953843\n"
     ]
    }
   ],
   "source": [
    "# stratified KFold\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "\n",
    "# cross validation\n",
    "forest_score = cross_val_score(forest, X_enn, y_enn, cv=kf)\n",
    "\n",
    "print('Scores: ', forest_score)\n",
    "print(\"Average 5-Fold Scores: {}\".format(np.mean(forest_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8436915358608018\n",
      "Accuracy Score, Test Set: 0.8435924791277197\n",
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.03      0.31      0.06       462\n",
      "        Good       0.94      0.90      0.92     93715\n",
      "        Poor       0.21      0.19      0.20      7992\n",
      "\n",
      "    accuracy                           0.84    102169\n",
      "   macro avg       0.39      0.47      0.39    102169\n",
      "weighted avg       0.88      0.84      0.86    102169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train_enn, y_train_enn)\n",
    "gaussian_pred = gaussian.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n\\n {}'.format(classification_report(y_test_enn, gaussian_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
