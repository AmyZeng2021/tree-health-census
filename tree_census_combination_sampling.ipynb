{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Overview - Combination Under and Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import (cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (classification_report,\n",
    "                             confusion_matrix)\n",
    "import imblearn\n",
    "from imblearn.combine import (SMOTETomek, SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_l</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_l</th>\n",
       "      <th>root_grate_l</th>\n",
       "      <th>root_other_l</th>\n",
       "      <th>trunk_wire_l</th>\n",
       "      <th>trnk_light_l</th>\n",
       "      <th>trnk_other_l</th>\n",
       "      <th>...</th>\n",
       "      <th>OnCurb</th>\n",
       "      <th>Harmful</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_l  num_problems  tree_dbh  root_stone_l  root_grate_l  \\\n",
       "0   Fair         1             0         3             0             0   \n",
       "1   Fair         1             1        21             1             0   \n",
       "2   Good         2             0         3             0             0   \n",
       "3   Good         2             1        10             1             0   \n",
       "4   Good         2             1        21             1             0   \n",
       "\n",
       "   root_other_l  trunk_wire_l  trnk_light_l  trnk_other_l  ...  OnCurb  \\\n",
       "0             0             0             0             0  ...       1   \n",
       "1             0             0             0             0  ...       1   \n",
       "2             0             0             0             0  ...       1   \n",
       "3             0             0             0             0  ...       1   \n",
       "4             0             0             0             0  ...       1   \n",
       "\n",
       "   Harmful  Helpful  Unsure  Damage  Bronx  Brooklyn  Manhattan  Queens  \\\n",
       "0        0        0       0       0      0         0          0       1   \n",
       "1        0        0       0       1      0         0          0       1   \n",
       "2        0        0       0       1      0         1          0       0   \n",
       "3        0        0       0       1      0         1          0       0   \n",
       "4        0        0       0       1      0         1          0       0   \n",
       "\n",
       "   Staten Island  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducible results\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate variables using train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health_l') # keep the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488651, 24) (488651,)\n",
      "(162884, 24) (162884,)\n"
     ]
    }
   ],
   "source": [
    "# target variable = health\n",
    "y = tree_ml['health'].values\n",
    "X = tree_ml.drop('health', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the control for our models. The accuracy scores show the success rates we should expect based on the strategies used for simple guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_frequent 0.8108960978364972\n",
      "stratified 0.6815525159008865\n",
      "uniform 0.3338879202377152\n",
      "constant 0.8108960978364972\n"
     ]
    }
   ],
   "source": [
    "strategies = ['most_frequent', 'stratified', 'uniform', 'constant'] # strategies available\n",
    "  \n",
    "for s in strategies: \n",
    "    if s =='constant': \n",
    "        dummy_classifier = DummyClassifier(strategy=s, random_state=42, constant='Good') \n",
    "    else: \n",
    "        dummy_classifier = DummyClassifier(strategy=s, random_state=42) \n",
    "    dummy_classifier.fit(X_train, y_train) \n",
    "    score = dummy_classifier.score(X_test, y_test) \n",
    "    print(s, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Tomek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method combines over sampling using SMOTE and under sampling by Tomek Links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Poor': 528308, 'Fair': 528226, 'Good': 528213})\n",
      "(1188560, 24) (1188560,)\n",
      "(396187, 24) (396187,)\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_smt, y_smt = smt.fit_sample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_smt)))\n",
    "\n",
    "# train test split\n",
    "X_train_smt, X_test_smt, y_train_smt, y_test_smt = train_test_split(X_smt, y_smt, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_smt.shape, y_train_smt.shape)\n",
    "print(X_test_smt.shape, y_test_smt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.42051894729757017\n",
      "Accuracy Score, Test Set:  0.41956197452213223\n",
      "Confusion Matrix: \n",
      " [[23417 55601 53500]\n",
      " [17525 69329 44609]\n",
      " [16413 42314 73479]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.18      0.25    132518\n",
      "        Good       0.41      0.53      0.46    131463\n",
      "        Poor       0.43      0.56      0.48    132206\n",
      "\n",
      "    accuracy                           0.42    396187\n",
      "   macro avg       0.42      0.42      0.40    396187\n",
      "weighted avg       0.42      0.42      0.40    396187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train_smt, y_train_smt)\n",
    "y_pred = logreg.predict(X_test_smt)\n",
    "    \n",
    "print('Logistic Regression \\n')\n",
    "    \n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_smt, y_train_smt))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_smt, y_test_smt))\n",
    "    \n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_smt, y_pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_smt, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.4470291781651747\n",
      "Accuracy Score, Test Set:  0.43683664532152744\n",
      "Confusion Matrix: \n",
      " [[66133 41977 24408]\n",
      " [52596 57872 20995]\n",
      " [48439 34703 49064]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.50      0.44    132518\n",
      "        Good       0.43      0.44      0.44    131463\n",
      "        Poor       0.52      0.37      0.43    132206\n",
      "\n",
      "    accuracy                           0.44    396187\n",
      "   macro avg       0.45      0.44      0.44    396187\n",
      "weighted avg       0.45      0.44      0.44    396187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# k-nearest neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_smt, y_train_smt)\n",
    "y_pred = knn.predict(X_test_smt)\n",
    "    \n",
    "print('KNN Classifier \\n')\n",
    "    \n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train_smt, y_train_smt))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test_smt, y_test_smt))\n",
    "    \n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_smt, y_pred)    \n",
    "print('Confusion Matrix: \\n', cm)\n",
    "\n",
    "# classificatin report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_smt, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5035967893922056\n",
      "Accuracy Score, Test Set: 0.48834010202252975\n",
      "Confusion Matrix: \n",
      " [[42321 50050 40147]\n",
      " [23534 74655 33274]\n",
      " [16425 39283 76498]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.51      0.32      0.39    132518\n",
      "        Good       0.46      0.57      0.51    131463\n",
      "        Poor       0.51      0.58      0.54    132206\n",
      "\n",
      "    accuracy                           0.49    396187\n",
      "   macro avg       0.49      0.49      0.48    396187\n",
      "weighted avg       0.49      0.49      0.48    396187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_smt, y_train_smt)\n",
    "y_pred = decision_tree.predict(X_test_smt)\n",
    "    \n",
    "print('Decision Tree Classifier \\n')\n",
    "    \n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train_smt, y_train_smt))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test_smt, y_test_smt))\n",
    "    \n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_smt, y_pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_smt, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.503583327724305\n",
      "Accuracy Score, Test Set: 0.4892209991746322\n",
      "Confusion Matrix: \n",
      " [[41723 50677 40118]\n",
      " [22779 75613 33071]\n",
      " [16271 39448 76487]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.52      0.31      0.39    132518\n",
      "        Good       0.46      0.58      0.51    131463\n",
      "        Poor       0.51      0.58      0.54    132206\n",
      "\n",
      "    accuracy                           0.49    396187\n",
      "   macro avg       0.49      0.49      0.48    396187\n",
      "weighted avg       0.49      0.49      0.48    396187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_smt, y_train_smt)\n",
    "y_pred = rf.predict(X_test_smt)\n",
    "    \n",
    "print('Random Forest Classifier \\n')\n",
    "    \n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', rf.score(X_train_smt, y_train_smt))\n",
    "print('Accuracy Score, Test Set:', rf.score(X_test_smt, y_test_smt))\n",
    "    \n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_smt, y_pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_smt, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.37264589082587335\n",
      "Accuracy Score, Test Set: 0.3720263410965024\n",
      "Confusion Matrix: \n",
      " [[ 12282  11264 108972]\n",
      " [ 10767  18364 102332]\n",
      " [  8296   7164 116746]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.09      0.15    132518\n",
      "        Good       0.50      0.14      0.22    131463\n",
      "        Poor       0.36      0.88      0.51    132206\n",
      "\n",
      "    accuracy                           0.37    396187\n",
      "   macro avg       0.42      0.37      0.29    396187\n",
      "weighted avg       0.42      0.37      0.29    396187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train_smt, y_train_smt)\n",
    "y_pred = gaussian.predict(X_test_smt)\n",
    "    \n",
    "print('Gaussian Naive Bayes \\n')\n",
    "    \n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_smt, y_train_smt))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_smt, y_test_smt))\n",
    "    \n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_smt, y_pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_smt, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE ENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method uses a combination of SMOTE (Synthetic Minority Over-sampling Technique) over sampling and under sampling using Edited Nearest Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Good': 82562, 'Poor': 74722, 'Fair': 69648})\n",
      "(1188560, 24) (1188560,)\n",
      "(396187, 24) (396187,)\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sme = SMOTEENN(random_state=42)\n",
    "X_senn, y_senn = sme.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_senn)))\n",
    "\n",
    "# train test split\n",
    "X_train_senn, X_test_senn, y_train_senn, y_test_senn = train_test_split(X_smt, y_smt, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_senn.shape, y_train_senn.shape)\n",
    "print(X_test_senn.shape, y_test_senn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.42051894729757017\n",
      "Accuracy Score, Test Set:  0.41956197452213223\n",
      "Confusion Matrix: \n",
      " [[23417 55601 53500]\n",
      " [17525 69329 44609]\n",
      " [16413 42314 73479]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.18      0.25    132518\n",
      "        Good       0.41      0.53      0.46    131463\n",
      "        Poor       0.43      0.56      0.48    132206\n",
      "\n",
      "    accuracy                           0.42    396187\n",
      "   macro avg       0.42      0.42      0.40    396187\n",
      "weighted avg       0.42      0.42      0.40    396187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train_senn, y_train_senn)\n",
    "y_pred = logreg.predict(X_test_senn)\n",
    "    \n",
    "print('Logistic Regression \\n')\n",
    "    \n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_senn, y_train_senn))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_senn, y_test_senn))\n",
    "    \n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_senn, y_pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_senn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.4470291781651747\n",
      "Accuracy Score, Test Set:  0.43683664532152744\n",
      "Confusion Matrix: \n",
      " [[66133 41977 24408]\n",
      " [52596 57872 20995]\n",
      " [48439 34703 49064]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.50      0.44    132518\n",
      "        Good       0.43      0.44      0.44    131463\n",
      "        Poor       0.52      0.37      0.43    132206\n",
      "\n",
      "    accuracy                           0.44    396187\n",
      "   macro avg       0.45      0.44      0.44    396187\n",
      "weighted avg       0.45      0.44      0.44    396187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# k-nearest neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_senn, y_train_senn)\n",
    "y_pred = knn.predict(X_test_senn)\n",
    "    \n",
    "print('KNN Classifier \\n')\n",
    "    \n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train_senn, y_train_senn))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test_senn, y_test_senn))\n",
    "    \n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_senn, y_pred)    \n",
    "print('Confusion Matrix: \\n', cm)\n",
    "\n",
    "# classificatin report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_senn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5035967893922056\n",
      "Accuracy Score, Test Set: 0.48834010202252975\n",
      "Confusion Matrix: \n",
      " [[42321 50050 40147]\n",
      " [23534 74655 33274]\n",
      " [16425 39283 76498]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.51      0.32      0.39    132518\n",
      "        Good       0.46      0.57      0.51    131463\n",
      "        Poor       0.51      0.58      0.54    132206\n",
      "\n",
      "    accuracy                           0.49    396187\n",
      "   macro avg       0.49      0.49      0.48    396187\n",
      "weighted avg       0.49      0.49      0.48    396187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_senn, y_train_senn)\n",
    "y_pred = decision_tree.predict(X_test_senn)\n",
    "    \n",
    "print('Decision Tree Classifier \\n')\n",
    "    \n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train_senn, y_train_senn))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test_senn, y_test_senn))\n",
    "    \n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_senn, y_pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_senn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.503583327724305\n",
      "Accuracy Score, Test Set: 0.4892209991746322\n",
      "Confusion Matrix: \n",
      " [[41723 50677 40118]\n",
      " [22779 75613 33071]\n",
      " [16271 39448 76487]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.52      0.31      0.39    132518\n",
      "        Good       0.46      0.58      0.51    131463\n",
      "        Poor       0.51      0.58      0.54    132206\n",
      "\n",
      "    accuracy                           0.49    396187\n",
      "   macro avg       0.49      0.49      0.48    396187\n",
      "weighted avg       0.49      0.49      0.48    396187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_senn, y_train_senn)\n",
    "y_pred = rf.predict(X_test_senn)\n",
    "    \n",
    "print('Random Forest Classifier \\n')\n",
    "    \n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', rf.score(X_train_senn, y_train_senn))\n",
    "print('Accuracy Score, Test Set:', rf.score(X_test_senn, y_test_senn))\n",
    "    \n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_senn, y_pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_senn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.37264589082587335\n",
      "Accuracy Score, Test Set: 0.3720263410965024\n",
      "Confusion Matrix: \n",
      " [[ 12282  11264 108972]\n",
      " [ 10767  18364 102332]\n",
      " [  8296   7164 116746]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.09      0.15    132518\n",
      "        Good       0.50      0.14      0.22    131463\n",
      "        Poor       0.36      0.88      0.51    132206\n",
      "\n",
      "    accuracy                           0.37    396187\n",
      "   macro avg       0.42      0.37      0.29    396187\n",
      "weighted avg       0.42      0.37      0.29    396187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train_senn, y_train_senn)\n",
    "y_pred = gaussian.predict(X_test_senn)\n",
    "    \n",
    "print('Gaussian Naive Bayes \\n')\n",
    "    \n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_senn, y_train_senn))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_senn, y_test_senn))\n",
    "    \n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_senn, y_pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_senn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
