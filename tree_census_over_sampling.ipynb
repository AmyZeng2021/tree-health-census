{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Overview - Over Sampling Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (classification_report,\n",
    "                             confusion_matrix)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import (RandomOverSampler,\n",
    "                                    SMOTE,\n",
    "                                    ADASYN, \n",
    "                                    BorderlineSMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_l</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_l</th>\n",
       "      <th>root_grate_l</th>\n",
       "      <th>root_other_l</th>\n",
       "      <th>trunk_wire_l</th>\n",
       "      <th>trnk_light_l</th>\n",
       "      <th>trnk_other_l</th>\n",
       "      <th>...</th>\n",
       "      <th>OnCurb</th>\n",
       "      <th>Harmful</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_l  num_problems  tree_dbh  root_stone_l  root_grate_l  \\\n",
       "0   Fair         1             0         3             0             0   \n",
       "1   Fair         1             1        21             1             0   \n",
       "2   Good         2             0         3             0             0   \n",
       "3   Good         2             1        10             1             0   \n",
       "4   Good         2             1        21             1             0   \n",
       "\n",
       "   root_other_l  trunk_wire_l  trnk_light_l  trnk_other_l  ...  OnCurb  \\\n",
       "0             0             0             0             0  ...       1   \n",
       "1             0             0             0             0  ...       1   \n",
       "2             0             0             0             0  ...       1   \n",
       "3             0             0             0             0  ...       1   \n",
       "4             0             0             0             0  ...       1   \n",
       "\n",
       "   Harmful  Helpful  Unsure  Damage  Bronx  Brooklyn  Manhattan  Queens  \\\n",
       "0        0        0       0       0      0         0          0       1   \n",
       "1        0        0       0       1      0         0          0       1   \n",
       "2        0        0       0       1      0         1          0       0   \n",
       "3        0        0       0       1      0         1          0       0   \n",
       "4        0        0       0       1      0         1          0       0   \n",
       "\n",
       "   Staten Island  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate variables using train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health_l') # keep the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488651, 24) (488651,)\n",
      "(162884, 24) (162884,)\n"
     ]
    }
   ],
   "source": [
    "# target variable = health\n",
    "y = tree_ml['health'].values\n",
    "X = tree_ml.drop('health', axis=1).values\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## algorithm functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "\n",
    "def logreg(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression(random_state=42)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    print('Logistic Regression \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-nearest neighbors\n",
    "\n",
    "def knn(X_train, X_test, y_train, y_test):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print('KNN Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set: ', knn.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set: ', knn.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "    # classificatin report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "\n",
    "def decision_tree(X_train, X_test, y_train, y_test):\n",
    "    decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    \n",
    "    print('Decision Tree Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "\n",
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Random Forest Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', rf.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', rf.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian naive bayes\n",
    "\n",
    "def gaussian(X_train, X_test, y_train, y_test):\n",
    "    gaussian = GaussianNB()\n",
    "    gaussian.fit(X_train, y_train)\n",
    "    y_pred = gaussian.predict(X_test)\n",
    "    \n",
    "    print('Gaussian Naive Bayes \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the control for our models. The accuracy scores show the success rates we should expect based on the strategies used for simple guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_frequent 0.8108960978364972\n",
      "stratified 0.6815525159008865\n",
      "uniform 0.3338879202377152\n",
      "constant 0.8108960978364972\n"
     ]
    }
   ],
   "source": [
    "strategies = ['most_frequent', 'stratified', 'uniform', 'constant'] # strategies available\n",
    "  \n",
    "for s in strategies: \n",
    "    if s =='constant': \n",
    "        dummy_classifier = DummyClassifier(strategy=s, random_state=42, constant='Good') \n",
    "    else: \n",
    "        dummy_classifier = DummyClassifier(strategy=s, random_state=42) \n",
    "    dummy_classifier.fit(X_train, y_train) \n",
    "    score = dummy_classifier.score(X_test, y_test) \n",
    "    print(s, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Over Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This standard method of over sampling selects minority samples and replicates them until they match the number of samples of the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Fair': 528327, 'Good': 528327, 'Poor': 528327})\n",
      "(1188735, 24) (1188735,)\n",
      "(396246, 24) (396246,)\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_ros)))\n",
    "\n",
    "# train test split\n",
    "X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_ros, y_ros, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_rs.shape, y_train_rs.shape)\n",
    "print(X_test_rs.shape, y_test_rs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.41811673754032647\n",
      "Accuracy Score, Test Set:  0.41762945241087607\n",
      "Confusion Matrix: \n",
      " [[22399 57764 52337]\n",
      " [17426 72130 41971]\n",
      " [17132 44132 70955]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.17      0.24    132500\n",
      "        Good       0.41      0.55      0.47    131527\n",
      "        Poor       0.43      0.54      0.48    132219\n",
      "\n",
      "    accuracy                           0.42    396246\n",
      "   macro avg       0.41      0.42      0.40    396246\n",
      "weighted avg       0.41      0.42      0.39    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.45203262291427443\n",
      "Accuracy Score, Test Set:  0.44320699767316263\n",
      "Confusion Matrix: \n",
      " [[61902 42854 27744]\n",
      " [49181 58340 24006]\n",
      " [40267 36575 55377]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.47      0.44    132500\n",
      "        Good       0.42      0.44      0.43    131527\n",
      "        Poor       0.52      0.42      0.46    132219\n",
      "\n",
      "    accuracy                           0.44    396246\n",
      "   macro avg       0.45      0.44      0.44    396246\n",
      "weighted avg       0.45      0.44      0.44    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5073813760005383\n",
      "Accuracy Score, Test Set: 0.4940945776108781\n",
      "Confusion Matrix: \n",
      " [[42823 51598 38079]\n",
      " [22784 76455 32288]\n",
      " [15741 39973 76505]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.53      0.32      0.40    132500\n",
      "        Good       0.46      0.58      0.51    131527\n",
      "        Poor       0.52      0.58      0.55    132219\n",
      "\n",
      "    accuracy                           0.49    396246\n",
      "   macro avg       0.50      0.49      0.49    396246\n",
      "weighted avg       0.50      0.49      0.49    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5073645513928672\n",
      "Accuracy Score, Test Set: 0.49455893561070646\n",
      "Confusion Matrix: \n",
      " [[42082 52014 38404]\n",
      " [22240 77021 32266]\n",
      " [15405 39950 76864]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.53      0.32      0.40    132500\n",
      "        Good       0.46      0.59      0.51    131527\n",
      "        Poor       0.52      0.58      0.55    132219\n",
      "\n",
      "    accuracy                           0.49    396246\n",
      "   macro avg       0.50      0.49      0.49    396246\n",
      "weighted avg       0.50      0.49      0.49    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.39208654578186053\n",
      "Accuracy Score, Test Set: 0.391463888594459\n",
      "Confusion Matrix: \n",
      " [[  8068  99386  25046]\n",
      " [  6005 114101  11421]\n",
      " [  6122  93150  32947]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.06      0.11    132500\n",
      "        Good       0.37      0.87      0.52    131527\n",
      "        Poor       0.47      0.25      0.33    132219\n",
      "\n",
      "    accuracy                           0.39    396246\n",
      "   macro avg       0.42      0.39      0.32    396246\n",
      "weighted avg       0.42      0.39      0.32    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The over sampling method SMOTE, or Synthetic Minority Over-sampling Technique, selects minority samples and increases them randomly to match the majority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Fair': 528327, 'Good': 528327, 'Poor': 528327})\n",
      "(1188735, 24) (1188735,)\n",
      "(396246, 24) (396246,)\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sm = SMOTE(random_state=42)\n",
    "X_sm, y_sm = sm.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_sm)))\n",
    "\n",
    "# train test split\n",
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm, y_sm, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_sm.shape, y_train_sm.shape)\n",
    "print(X_test_sm.shape, y_test_sm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.4214496923199872\n",
      "Accuracy Score, Test Set:  0.42101119001832193\n",
      "Confusion Matrix: \n",
      " [[23522 55238 53740]\n",
      " [17543 68883 45101]\n",
      " [16377 41423 74419]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.18      0.25    132500\n",
      "        Good       0.42      0.52      0.46    131527\n",
      "        Poor       0.43      0.56      0.49    132219\n",
      "\n",
      "    accuracy                           0.42    396246\n",
      "   macro avg       0.42      0.42      0.40    396246\n",
      "weighted avg       0.42      0.42      0.40    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.448361493520423\n",
      "Accuracy Score, Test Set:  0.4374176647839978\n",
      "Confusion Matrix: \n",
      " [[67601 37578 27321]\n",
      " [56202 51329 23996]\n",
      " [47934 29890 54395]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.51      0.44    132500\n",
      "        Good       0.43      0.39      0.41    131527\n",
      "        Poor       0.51      0.41      0.46    132219\n",
      "\n",
      "    accuracy                           0.44    396246\n",
      "   macro avg       0.45      0.44      0.44    396246\n",
      "weighted avg       0.45      0.44      0.44    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5036522017102214\n",
      "Accuracy Score, Test Set: 0.4879594999066237\n",
      "Confusion Matrix: \n",
      " [[42766 49811 39923]\n",
      " [24014 74305 33208]\n",
      " [16470 39468 76281]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.51      0.32      0.40    132500\n",
      "        Good       0.45      0.56      0.50    131527\n",
      "        Poor       0.51      0.58      0.54    132219\n",
      "\n",
      "    accuracy                           0.49    396246\n",
      "   macro avg       0.49      0.49      0.48    396246\n",
      "weighted avg       0.49      0.49      0.48    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5036387420240844\n",
      "Accuracy Score, Test Set: 0.4890875870040329\n",
      "Confusion Matrix: \n",
      " [[42019 50418 40063]\n",
      " [23087 75340 33100]\n",
      " [16209 39570 76440]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.52      0.32      0.39    132500\n",
      "        Good       0.46      0.57      0.51    131527\n",
      "        Poor       0.51      0.58      0.54    132219\n",
      "\n",
      "    accuracy                           0.49    396246\n",
      "   macro avg       0.49      0.49      0.48    396246\n",
      "weighted avg       0.49      0.49      0.48    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.370339899136477\n",
      "Accuracy Score, Test Set: 0.37038354961311915\n",
      "Confusion Matrix: \n",
      " [[ 11964  10155 110381]\n",
      " [ 10461  16665 104401]\n",
      " [  8067   6018 118134]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.09      0.15    132500\n",
      "        Good       0.51      0.13      0.20    131527\n",
      "        Poor       0.35      0.89      0.51    132219\n",
      "\n",
      "    accuracy                           0.37    396246\n",
      "   macro avg       0.42      0.37      0.29    396246\n",
      "weighted avg       0.42      0.37      0.29    396246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_sm, X_test_sm, y_train_sm, y_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADASYN - Adaptive Synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Adaptive Synthetic method, or ADASYN, is similar to SMOTE over sampling. However, ADASYN selectively generates sample points around minority samples using a density distributor and does not create uniform weights like SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Poor': 535394, 'Good': 528327, 'Fair': 526527})\n",
      "(1192686, 24) (1192686,)\n",
      "(397562, 24) (397562,)\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "ada = ADASYN(random_state=42)\n",
    "X_ada, y_ada = ada.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_ada)))\n",
    "\n",
    "# train test split\n",
    "X_train_ada, X_test_ada, y_train_ada, y_test_ada = train_test_split(X_ada, y_ada, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_ada.shape, y_train_ada.shape)\n",
    "print(X_test_ada.shape, y_test_ada.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.4091043241892669\n",
      "Accuracy Score, Test Set:  0.40859538889531694\n",
      "Confusion Matrix: \n",
      " [[19791 53097 59200]\n",
      " [16488 64845 50064]\n",
      " [14411 41860 77806]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.15      0.22    132088\n",
      "        Good       0.41      0.49      0.45    131397\n",
      "        Poor       0.42      0.58      0.48    134077\n",
      "\n",
      "    accuracy                           0.41    397562\n",
      "   macro avg       0.40      0.41      0.38    397562\n",
      "weighted avg       0.40      0.41      0.38    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.4336757537189168\n",
      "Accuracy Score, Test Set:  0.42309375644553554\n",
      "Confusion Matrix: \n",
      " [[69485 37184 25419]\n",
      " [60158 49565 21674]\n",
      " [55579 29342 49156]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.53      0.44    132088\n",
      "        Good       0.43      0.38      0.40    131397\n",
      "        Poor       0.51      0.37      0.43    134077\n",
      "\n",
      "    accuracy                           0.42    397562\n",
      "   macro avg       0.44      0.42      0.42    397562\n",
      "weighted avg       0.44      0.42      0.42    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.492267872684009\n",
      "Accuracy Score, Test Set: 0.4780361302136522\n",
      "Confusion Matrix: \n",
      " [[51724 38683 41681]\n",
      " [34633 59660 37104]\n",
      " [26044 29368 78665]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.46      0.39      0.42    132088\n",
      "        Good       0.47      0.45      0.46    131397\n",
      "        Poor       0.50      0.59      0.54    134077\n",
      "\n",
      "    accuracy                           0.48    397562\n",
      "   macro avg       0.48      0.48      0.47    397562\n",
      "weighted avg       0.48      0.48      0.47    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.49226032669118275\n",
      "Accuracy Score, Test Set: 0.4794547768649921\n",
      "Confusion Matrix: \n",
      " [[51005 39268 41815]\n",
      " [33686 60674 37037]\n",
      " [25746 29397 78934]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.46      0.39      0.42    132088\n",
      "        Good       0.47      0.46      0.47    131397\n",
      "        Poor       0.50      0.59      0.54    134077\n",
      "\n",
      "    accuracy                           0.48    397562\n",
      "   macro avg       0.48      0.48      0.48    397562\n",
      "weighted avg       0.48      0.48      0.48    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.36650467935399594\n",
      "Accuracy Score, Test Set: 0.36756027990602724\n",
      "Confusion Matrix: \n",
      " [[ 12858   7673 111557]\n",
      " [ 12945  12373 106079]\n",
      " [  8102   5078 120897]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.10      0.15    132088\n",
      "        Good       0.49      0.09      0.16    131397\n",
      "        Poor       0.36      0.90      0.51    134077\n",
      "\n",
      "    accuracy                           0.37    397562\n",
      "   macro avg       0.41      0.36      0.27    397562\n",
      "weighted avg       0.41      0.37      0.28    397562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_ada, X_test_ada, y_train_ada, y_test_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Extensions - Borderline SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Borderline SMOTE](https://link.springer.com/chapter/10.1007/11538059_91) is an over sampling method in which the minority samples on the cusp of being in the majority pile are oversampled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Fair': 528327, 'Good': 528327, 'Poor': 528327})\n",
      "(1267984, 24) (1267984,)\n",
      "(316997, 24) (316997,)\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "bsmt = BorderlineSMOTE(random_state=42)\n",
    "X_bsmt, y_bsmt = bsmt.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_bsmt)))\n",
    "\n",
    "# train test split\n",
    "X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt = train_test_split(X_bsmt, y_bsmt, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train_bsmt.shape, y_train_bsmt.shape)\n",
    "print(X_test_bsmt.shape, y_test_bsmt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.473412913727618\n",
      "Accuracy Score, Test Set:  0.4722284438023073\n",
      "Confusion Matrix: \n",
      " [[20060 52371 33588]\n",
      " [15202 67595 22281]\n",
      " [14798 29062 62040]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.19      0.26    106019\n",
      "        Good       0.45      0.64      0.53    105078\n",
      "        Poor       0.53      0.59      0.55    105900\n",
      "\n",
      "    accuracy                           0.47    316997\n",
      "   macro avg       0.46      0.47      0.45    316997\n",
      "weighted avg       0.46      0.47      0.45    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.5668541558884024\n",
      "Accuracy Score, Test Set:  0.5580210538270078\n",
      "Confusion Matrix: \n",
      " [[53594 32055 20370]\n",
      " [36165 52324 16589]\n",
      " [19724 15203 70973]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.49      0.51      0.50    106019\n",
      "        Good       0.53      0.50      0.51    105078\n",
      "        Poor       0.66      0.67      0.66    105900\n",
      "\n",
      "    accuracy                           0.56    316997\n",
      "   macro avg       0.56      0.56      0.56    316997\n",
      "weighted avg       0.56      0.56      0.56    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.627391986018751\n",
      "Accuracy Score, Test Set: 0.6139774193446625\n",
      "Confusion Matrix: \n",
      " [[53056 22910 30053]\n",
      " [31660 49408 24010]\n",
      " [ 8214  5521 92165]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.57      0.50      0.53    106019\n",
      "        Good       0.63      0.47      0.54    105078\n",
      "        Poor       0.63      0.87      0.73    105900\n",
      "\n",
      "    accuracy                           0.61    316997\n",
      "   macro avg       0.61      0.61      0.60    316997\n",
      "weighted avg       0.61      0.61      0.60    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.6273817335234514\n",
      "Accuracy Score, Test Set: 0.6151004583639593\n",
      "Confusion Matrix: \n",
      " [[52565 23291 30163]\n",
      " [31005 50126 23947]\n",
      " [ 8091  5515 92294]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.57      0.50      0.53    106019\n",
      "        Good       0.64      0.48      0.54    105078\n",
      "        Poor       0.63      0.87      0.73    105900\n",
      "\n",
      "    accuracy                           0.62    316997\n",
      "   macro avg       0.61      0.61      0.60    316997\n",
      "weighted avg       0.61      0.62      0.60    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4458045211926964\n",
      "Accuracy Score, Test Set: 0.44354362975043926\n",
      "Confusion Matrix: \n",
      " [[12467 59414 34138]\n",
      " [10998 74866 19214]\n",
      " [ 8980 43651 53269]]\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.12      0.18    106019\n",
      "        Good       0.42      0.71      0.53    105078\n",
      "        Poor       0.50      0.50      0.50    105900\n",
      "\n",
      "    accuracy                           0.44    316997\n",
      "   macro avg       0.43      0.44      0.40    316997\n",
      "weighted avg       0.43      0.44      0.40    316997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_bsmt, X_test_bsmt, y_train_bsmt, y_test_bsmt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
