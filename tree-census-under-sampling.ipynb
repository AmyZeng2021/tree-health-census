{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Under Sampling Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (KFold, \n",
    "                                     cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (mean_squared_error,\n",
    "                             classification_report,\n",
    "                             mean_absolute_error,\n",
    "                             accuracy_score,\n",
    "                             confusion_matrix,\n",
    "                             average_precision_score,\n",
    "                             precision_recall_curve,\n",
    "                             recall_score,\n",
    "                             f1_score)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import (RandomUnderSampler,\n",
    "                                     TomekLinks,\n",
    "                                     EditedNearestNeighbours,\n",
    "                                     NeighbourhoodCleaningRule,\n",
    "                                     NearMiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_l</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_l</th>\n",
       "      <th>root_grate_l</th>\n",
       "      <th>root_other_l</th>\n",
       "      <th>trunk_wire_l</th>\n",
       "      <th>trnk_light_l</th>\n",
       "      <th>trnk_other_l</th>\n",
       "      <th>...</th>\n",
       "      <th>OnCurb</th>\n",
       "      <th>Harmful</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_l  num_problems  tree_dbh  root_stone_l  root_grate_l  \\\n",
       "0   Fair         1             0         3             0             0   \n",
       "1   Fair         1             1        21             1             0   \n",
       "2   Good         2             0         3             0             0   \n",
       "3   Good         2             1        10             1             0   \n",
       "4   Good         2             1        21             1             0   \n",
       "\n",
       "   root_other_l  trunk_wire_l  trnk_light_l  trnk_other_l  ...  OnCurb  \\\n",
       "0             0             0             0             0  ...       1   \n",
       "1             0             0             0             0  ...       1   \n",
       "2             0             0             0             0  ...       1   \n",
       "3             0             0             0             0  ...       1   \n",
       "4             0             0             0             0  ...       1   \n",
       "\n",
       "   Harmful  Helpful  Unsure  Damage  Bronx  Brooklyn  Manhattan  Queens  \\\n",
       "0        0        0       0       0      0         0          0       1   \n",
       "1        0        0       0       1      0         0          0       1   \n",
       "2        0        0       0       1      0         1          0       0   \n",
       "3        0        0       0       1      0         1          0       0   \n",
       "4        0        0       0       1      0         1          0       0   \n",
       "\n",
       "   Staten Island  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target and Response Variable, Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health_l') # keep the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targe and response variable\n",
    "y = tree_ml['health'].values\n",
    "X = tree_ml.drop('health', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521228, 24) (521228,)\n",
      "(130307, 24) (130307,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6808935820792437\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dc_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6803042046858573\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_freq = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf_freq.fit(X_train, y_train)\n",
    "dc_pred_freq = dummy_clf_freq.predict(X_test)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Under Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random undersampling Counter({'Fair': 26781, 'Good': 26781, 'Poor': 26781})\n"
     ]
    }
   ],
   "source": [
    "random_under = RandomUnderSampler(random_state=42)\n",
    "X_rs, y_rs = random_under.fit_sample(X, y)\n",
    "\n",
    "print('Random undersampling {}'.format(Counter(y_rs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64274, 24) (64274,)\n",
      "(16069, 24) (16069,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_rs, y_rs, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train_rs.shape, y_train_rs.shape)\n",
    "print(X_test_rs.shape, y_test_rs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.4178672558110589\n",
      "Accuracy Score, Test Set:  0.41284460762959735\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.16      0.23      5315\n",
      "        Good       0.41      0.53      0.46      5369\n",
      "        Poor       0.42      0.54      0.48      5385\n",
      "\n",
      "    accuracy                           0.41     16069\n",
      "   macro avg       0.41      0.41      0.39     16069\n",
      "weighted avg       0.41      0.41      0.39     16069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42).fit(X_train_rs, y_train_rs)\n",
    "logreg_pred = logreg.predict(X_test_rs)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_rs, y_test_rs))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_rs, logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 865 2264 2186]\n",
      " [ 722 2846 1801]\n",
      " [ 665 1797 2923]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_rs, logreg_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.45264025889162024\n",
      "Accuracy Score, Test Set:  0.3849648391312465\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.35      0.46      0.40      5315\n",
      "        Good       0.39      0.40      0.40      5369\n",
      "        Poor       0.44      0.30      0.35      5385\n",
      "\n",
      "    accuracy                           0.38     16069\n",
      "   macro avg       0.39      0.39      0.38     16069\n",
      "weighted avg       0.39      0.38      0.38     16069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using 5 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train_rs, y_train_rs)\n",
    "knn_pred = knn.predict(X_test_rs)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test_rs, y_test_rs))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_rs, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[2456 1696 1163]\n",
      " [2346 2132  891]\n",
      " [2201 1586 1598]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_rs, knn_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5395183122257834\n",
      "Accuracy Score, Test Set: 0.40456780135664944\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.37      0.31      0.34      5315\n",
      "        Good       0.41      0.50      0.45      5369\n",
      "        Poor       0.43      0.40      0.42      5385\n",
      "\n",
      "    accuracy                           0.40     16069\n",
      "   macro avg       0.40      0.40      0.40     16069\n",
      "weighted avg       0.40      0.40      0.40     16069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train_rs, y_train_rs)\n",
    "decision_tree_pred = decision_tree.predict(X_test_rs)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test_rs, y_test_rs))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_rs, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[1639 2102 1574]\n",
      " [1429 2695 1245]\n",
      " [1393 1825 2167]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_rs, decision_tree_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5394871954445032\n",
      "Accuracy Score, Test Set: 0.4104798058373265\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.37      0.27      0.32      5315\n",
      "        Good       0.41      0.51      0.45      5369\n",
      "        Poor       0.43      0.45      0.44      5385\n",
      "\n",
      "    accuracy                           0.41     16069\n",
      "   macro avg       0.41      0.41      0.40     16069\n",
      "weighted avg       0.41      0.41      0.40     16069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(random_state=42).fit(X_train_rs, y_train_rs)\n",
    "rand_forest_pred = rand_forest.predict(X_test_rs)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', rand_forest.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set:', rand_forest.score(X_test_rs, y_test_rs))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_rs, rand_forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[1445 2087 1783]\n",
      " [1239 2717 1413]\n",
      " [1170 1781 2434]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_rs, rand_forest_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.3923670535519806\n",
      "Accuracy Score, Test Set: 0.3933038770303068\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.08      0.13      5315\n",
      "        Good       0.38      0.85      0.52      5369\n",
      "        Poor       0.47      0.24      0.32      5385\n",
      "\n",
      "    accuracy                           0.39     16069\n",
      "   macro avg       0.41      0.39      0.32     16069\n",
      "weighted avg       0.41      0.39      0.33     16069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB().fit(X_train_rs, y_train_rs)\n",
    "gaussian_pred = gaussian.predict(X_test_rs)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_rs, y_test_rs))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_rs, gaussian_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 420 3859 1036]\n",
      " [ 340 4585  444]\n",
      " [ 318 3752 1315]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_rs, gaussian_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.4167159349036936\n",
      "Accuracy Score, Test Set: 0.41085319559400085\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.26      0.31      5315\n",
      "        Good       0.40      0.62      0.49      5369\n",
      "        Poor       0.47      0.35      0.40      5385\n",
      "\n",
      "    accuracy                           0.41     16069\n",
      "   macro avg       0.41      0.41      0.40     16069\n",
      "weighted avg       0.41      0.41      0.40     16069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical = CategoricalNB().fit(X_train_rs, y_train_rs)\n",
    "categorical_pred = categorical.predict(X_test_rs)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train_rs, y_train_rs))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test_rs, y_test_rs))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_rs, categorical_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[1382 2615 1318]\n",
      " [1189 3349  831]\n",
      " [1059 2455 1871]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_rs, categorical_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TomekLinks undersampling Counter({'Good': 527892, 'Fair': 96026, 'Poor': 26781})\n"
     ]
    }
   ],
   "source": [
    "tomek = TomekLinks()\n",
    "X_tomek, y_tomek = tomek.fit_resample(X, y)\n",
    "\n",
    "print('TomekLinks undersampling {}'.format(Counter(y_tomek)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521228, 24) (521228,)\n",
      "(130307, 24) (130307,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_tl, X_test_tl, y_train_tl, y_test_tl = train_test_split(X_tomek, y_tomek, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.811295165389514\n",
      "Accuracy Score, Test Set:  0.810258183494698\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.32      0.02      0.03     19162\n",
      "        Good       0.81      1.00      0.90    105492\n",
      "        Poor       0.50      0.00      0.00      5486\n",
      "\n",
      "    accuracy                           0.81    130140\n",
      "   macro avg       0.54      0.34      0.31    130140\n",
      "weighted avg       0.73      0.81      0.73    130140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42).fit(X_train_tl, y_train_tl)\n",
    "logreg_pred = logreg.predict(X_test_tl)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_tl, y_train_tl))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_tl, y_test_tl))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_tl, logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[   304  18858      0]\n",
      " [   349 105142      1]\n",
      " [   296   5189      1]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_tl, logreg_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.8020205202484253\n",
      "Accuracy Score, Test Set:  0.7914246196403872\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.25      0.08      0.13     19162\n",
      "        Good       0.82      0.96      0.88    105492\n",
      "        Poor       0.37      0.02      0.04      5486\n",
      "\n",
      "    accuracy                           0.79    130140\n",
      "   macro avg       0.48      0.36      0.35    130140\n",
      "weighted avg       0.72      0.79      0.74    130140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using 5 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train_tl, y_train_tl)\n",
    "knn_pred = knn.predict(X_test_tl)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train_tl, y_train_tl))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test_tl, y_test_tl))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_tl, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  1620  17441    101]\n",
      " [  4132 101250    110]\n",
      " [   607   4753    126]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_tl, knn_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8250899513791905\n",
      "Accuracy Score, Test Set: 0.8019594283079761\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.31      0.06      0.10     19162\n",
      "        Good       0.82      0.98      0.89    105492\n",
      "        Poor       0.27      0.03      0.06      5486\n",
      "\n",
      "    accuracy                           0.80    130140\n",
      "   macro avg       0.46      0.36      0.35    130140\n",
      "weighted avg       0.72      0.80      0.74    130140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train_tl, y_train_tl)\n",
    "decision_tree_pred = decision_tree.predict(X_test_tl)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train_tl, y_train_tl))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test_tl, y_test_tl))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_tl, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  1140  17836    186]\n",
      " [  2156 103055    281]\n",
      " [   434   4880    172]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_tl, decision_tree_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8250861093555197\n",
      "Accuracy Score, Test Set: 0.8055478715229752\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.33      0.04      0.08     19162\n",
      "        Good       0.82      0.98      0.89    105492\n",
      "        Poor       0.27      0.03      0.06      5486\n",
      "\n",
      "    accuracy                           0.81    130140\n",
      "   macro avg       0.47      0.35      0.34    130140\n",
      "weighted avg       0.72      0.81      0.74    130140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(random_state=42).fit(X_train_tl, y_train_tl)\n",
    "rand_forest_pred = rand_forest.predict(X_test_tl)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', rand_forest.score(X_train_tl, y_train_tl))\n",
    "print('Accuracy Score, Test Set:', rand_forest.score(X_test_tl, y_test_tl))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_tl, rand_forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[   845  18113    204]\n",
      " [  1398 103801    293]\n",
      " [   339   4959    188]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_tl, rand_forest_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.7354536181297413\n",
      "Accuracy Score, Test Set: 0.7340940525587828\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.21      0.11      0.15     19162\n",
      "        Good       0.83      0.87      0.85    105492\n",
      "        Poor       0.12      0.19      0.15      5486\n",
      "\n",
      "    accuracy                           0.73    130140\n",
      "   macro avg       0.39      0.39      0.38    130140\n",
      "weighted avg       0.71      0.73      0.72    130140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB().fit(X_train_tl, y_train_tl)\n",
    "gaussian_pred = gaussian.predict(X_test_tl)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_tl, y_train_tl))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_tl, y_test_tl))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_tl, gaussian_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 2191 14579  2392]\n",
      " [ 7803 92300  5389]\n",
      " [  554  3888  1044]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_tl, gaussian_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8015095311002212\n",
      "Accuracy Score, Test Set: 0.8003150453357922\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.28      0.06      0.10     19162\n",
      "        Good       0.82      0.97      0.89    105492\n",
      "        Poor       0.34      0.04      0.07      5486\n",
      "\n",
      "    accuracy                           0.80    130140\n",
      "   macro avg       0.48      0.36      0.35    130140\n",
      "weighted avg       0.72      0.80      0.74    130140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical = CategoricalNB().fit(X_train_tl, y_train_tl)\n",
    "categorical_pred = categorical.predict(X_test_tl)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train_tl, y_train_tl))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test_tl, y_test_tl))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_tl, categorical_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  1159  17813    190]\n",
      " [  2486 102775    231]\n",
      " [   480   4787    219]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_tl, categorical_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edited Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Good': 312229, 'Poor': 26781, 'Fair': 1553})\n"
     ]
    }
   ],
   "source": [
    "enn = EditedNearestNeighbours()\n",
    "X_enn, y_enn = enn.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_enn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272450, 24) (272450,)\n",
      "(68113, 24) (68113,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_enn, X_test_enn, y_train_enn, y_test_enn = train_test_split(X_enn, y_enn, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train_enn.shape, y_train_enn.shape)\n",
    "print(X_test_enn.shape, y_test_enn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.921002018719031\n",
      "Accuracy Score, Test Set:  0.9223643063732327\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.12      0.00      0.01       328\n",
      "        Good       0.93      1.00      0.96     62504\n",
      "        Poor       0.64      0.10      0.17      5281\n",
      "\n",
      "    accuracy                           0.92     68113\n",
      "   macro avg       0.56      0.37      0.38     68113\n",
      "weighted avg       0.90      0.92      0.89     68113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42).fit(X_train_enn, y_train_enn)\n",
    "logreg_pred = logreg.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_enn, logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[    1   235    92]\n",
      " [    0 62295   209]\n",
      " [    7  4745   529]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_enn, logreg_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.9559258579555882\n",
      "Accuracy Score, Test Set:  0.9524907139606242\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.68      0.70      0.69       328\n",
      "        Good       0.96      1.00      0.98     62504\n",
      "        Poor       0.90      0.45      0.60      5281\n",
      "\n",
      "    accuracy                           0.95     68113\n",
      "   macro avg       0.84      0.71      0.75     68113\n",
      "weighted avg       0.95      0.95      0.95     68113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using 5 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train_enn, y_train_enn)\n",
    "knn_pred = knn.predict(X_test_enn)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_enn, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  228    46    54]\n",
      " [    8 62295   201]\n",
      " [  101  2826  2354]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_enn, knn_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.9652817030647826\n",
      "Accuracy Score, Test Set: 0.9564253519886071\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.73      0.84      0.78       328\n",
      "        Good       0.96      1.00      0.98     62504\n",
      "        Poor       0.91      0.49      0.64      5281\n",
      "\n",
      "    accuracy                           0.96     68113\n",
      "   macro avg       0.87      0.78      0.80     68113\n",
      "weighted avg       0.95      0.96      0.95     68113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train_enn, y_train_enn)\n",
    "decision_tree_pred = decision_tree.predict(X_test_enn)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_enn, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  277    15    36]\n",
      " [   13 62274   217]\n",
      " [   92  2595  2594]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_enn, decision_tree_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.9652817030647826\n",
      "Accuracy Score, Test Set: 0.9582018116952711\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.77      0.84      0.80       328\n",
      "        Good       0.96      1.00      0.98     62504\n",
      "        Poor       0.95      0.49      0.65      5281\n",
      "\n",
      "    accuracy                           0.96     68113\n",
      "   macro avg       0.89      0.78      0.81     68113\n",
      "weighted avg       0.96      0.96      0.95     68113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(random_state=42).fit(X_train_enn, y_train_enn)\n",
    "rand_forest_pred = rand_forest.predict(X_test_enn)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', rand_forest.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set:', rand_forest.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_enn, rand_forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  274    18    36]\n",
      " [    3 62394   107]\n",
      " [   78  2605  2598]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_enn, rand_forest_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8437438062029731\n",
      "Accuracy Score, Test Set: 0.8444496645280637\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.03      0.34      0.06       328\n",
      "        Good       0.94      0.90      0.92     62504\n",
      "        Poor       0.21      0.19      0.20      5281\n",
      "\n",
      "    accuracy                           0.84     68113\n",
      "   macro avg       0.39      0.48      0.39     68113\n",
      "weighted avg       0.88      0.84      0.86     68113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB().fit(X_train_enn, y_train_enn)\n",
    "gaussian_pred = gaussian.predict(X_test_enn)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_enn, gaussian_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[  111    55   162]\n",
      " [ 2523 56408  3573]\n",
      " [  602  3680   999]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_enn, gaussian_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IndexError: index 9 is out of bounds for axis 1 with size 9\n",
    "# categorical = CategoricalNB().fit(X_train_enn, y_train_enn)\n",
    "# categorical_pred = categorical.predict(X_test_enn)\n",
    "\n",
    "# # accuracy score\n",
    "# print('Accuracy Score, Training Set:', categorical.score(X_train_enn, y_train_enn))\n",
    "# print('Accuracy Score, Test Set:', categorical.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# # classification report\n",
    "# print('Classification Report \\n')\n",
    "# print(classification_report(y_test_enn, categorical_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # confusion matrix\n",
    "# cm = confusion_matrix(y_test_enn, categorical_pred)\n",
    "\n",
    "# print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Fair': 26781, 'Good': 26781, 'Poor': 26781})\n"
     ]
    }
   ],
   "source": [
    "nm = NearMiss()\n",
    "X_nm, y_nm = nm.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60257, 24) (60257,)\n",
      "(20086, 24) (20086,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train_nm, X_test_nm, y_train_nm, y_test_nm = train_test_split(X_nm, y_nm, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_nm.shape, y_train_nm.shape)\n",
    "print(X_test_nm.shape, y_test_nm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.44751647111538906\n",
      "Accuracy Score, Test Set:  0.4448869859603704\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.38      0.38      6648\n",
      "        Good       0.43      0.60      0.50      6744\n",
      "        Poor       0.59      0.35      0.44      6694\n",
      "\n",
      "    accuracy                           0.44     20086\n",
      "   macro avg       0.47      0.44      0.44     20086\n",
      "weighted avg       0.47      0.44      0.44     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42).fit(X_train_nm, y_train_nm)\n",
    "logreg_pred = logreg.predict(X_test_nm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test_nm, y_test_nm))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_nm, logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[2553 3147  948]\n",
      " [2036 4019  689]\n",
      " [2063 2267 2364]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_nm, logreg_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.44540883216887667\n",
      "Accuracy Score, Test Set:  0.4092402668525341\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.36      0.49      0.41      6648\n",
      "        Good       0.40      0.42      0.41      6744\n",
      "        Poor       0.54      0.32      0.40      6694\n",
      "\n",
      "    accuracy                           0.41     20086\n",
      "   macro avg       0.43      0.41      0.41     20086\n",
      "weighted avg       0.43      0.41      0.41     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using 5 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train_nm, y_train_nm)\n",
    "knn_pred = knn.predict(X_test_nm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test_nm, y_test_nm))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_nm, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[3267 2377 1004]\n",
      " [3119 2818  807]\n",
      " [2794 1765 2135]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_nm, knn_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5063478102129213\n",
      "Accuracy Score, Test Set: 0.46883401374091405\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.43      0.42      6648\n",
      "        Good       0.44      0.60      0.51      6744\n",
      "        Poor       0.66      0.37      0.47      6694\n",
      "\n",
      "    accuracy                           0.47     20086\n",
      "   macro avg       0.50      0.47      0.47     20086\n",
      "weighted avg       0.50      0.47      0.47     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train_nm, y_train_nm)\n",
    "decision_tree_pred = decision_tree.predict(X_test_nm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test_nm, y_test_nm))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_nm, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[2891 2991  766]\n",
      " [2178 4076  490]\n",
      " [2118 2126 2450]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_nm, decision_tree_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5062648323016413\n",
      "Accuracy Score, Test Set: 0.47301603106641443\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.42      0.41      6648\n",
      "        Good       0.44      0.61      0.51      6744\n",
      "        Poor       0.65      0.39      0.48      6694\n",
      "\n",
      "    accuracy                           0.47     20086\n",
      "   macro avg       0.50      0.47      0.47     20086\n",
      "weighted avg       0.50      0.47      0.47     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(random_state=42).fit(X_train_nm, y_train_nm)\n",
    "rand_forest_pred = rand_forest.predict(X_test_nm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', rand_forest.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', rand_forest.score(X_test_nm, y_test_nm))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_nm, rand_forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[2795 3007  846]\n",
      " [2076 4124  544]\n",
      " [1968 2144 2582]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_nm, rand_forest_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.4020279801516836\n",
      "Accuracy Score, Test Set: 0.39744100368415813\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.30      0.09      0.14      6648\n",
      "        Good       0.37      0.93      0.53      6744\n",
      "        Poor       0.79      0.17      0.28      6694\n",
      "\n",
      "    accuracy                           0.40     20086\n",
      "   macro avg       0.49      0.40      0.32     20086\n",
      "weighted avg       0.49      0.40      0.32     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB().fit(X_train_nm, y_train_nm)\n",
    "gaussian_pred = gaussian.predict(X_test_nm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_nm, y_test_nm))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_nm, gaussian_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 589 5864  195]\n",
      " [ 383 6249  112]\n",
      " [ 981 4568 1145]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_nm, gaussian_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.45123388154073385\n",
      "Accuracy Score, Test Set: 0.4474758538285373\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.39      0.39      6648\n",
      "        Good       0.43      0.61      0.50      6744\n",
      "        Poor       0.62      0.34      0.44      6694\n",
      "\n",
      "    accuracy                           0.45     20086\n",
      "   macro avg       0.48      0.45      0.44     20086\n",
      "weighted avg       0.48      0.45      0.44     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical = CategoricalNB().fit(X_train_nm, y_train_nm)\n",
    "categorical_pred = categorical.predict(X_test_nm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test_nm, y_test_nm))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test_nm, categorical_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[2596 3215  837]\n",
      " [2059 4118  567]\n",
      " [2106 2314 2274]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test_nm, categorical_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
