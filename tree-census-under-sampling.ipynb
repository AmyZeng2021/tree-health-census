{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Under Sampling Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (KFold, \n",
    "                                     cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (mean_squared_error,\n",
    "                             classification_report,\n",
    "                             mean_absolute_error,\n",
    "                             accuracy_score,\n",
    "                             confusion_matrix,\n",
    "                             average_precision_score,\n",
    "                             precision_recall_curve,\n",
    "                             recall_score,\n",
    "                             f1_score)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import (RandomUnderSampler,\n",
    "                                     TomekLinks,\n",
    "                                     EditedNearestNeighbours,\n",
    "                                     NeighbourhoodCleaningRule,\n",
    "                                     NearMiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_l</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_l</th>\n",
       "      <th>root_grate_l</th>\n",
       "      <th>root_other_l</th>\n",
       "      <th>trunk_wire_l</th>\n",
       "      <th>trnk_light_l</th>\n",
       "      <th>trnk_other_l</th>\n",
       "      <th>...</th>\n",
       "      <th>OnCurb</th>\n",
       "      <th>Harmful</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_l  num_problems  tree_dbh  root_stone_l  root_grate_l  \\\n",
       "0   Fair         1             0         3             0             0   \n",
       "1   Fair         1             1        21             1             0   \n",
       "2   Good         2             0         3             0             0   \n",
       "3   Good         2             1        10             1             0   \n",
       "4   Good         2             1        21             1             0   \n",
       "\n",
       "   root_other_l  trunk_wire_l  trnk_light_l  trnk_other_l  ...  OnCurb  \\\n",
       "0             0             0             0             0  ...       1   \n",
       "1             0             0             0             0  ...       1   \n",
       "2             0             0             0             0  ...       1   \n",
       "3             0             0             0             0  ...       1   \n",
       "4             0             0             0             0  ...       1   \n",
       "\n",
       "   Harmful  Helpful  Unsure  Damage  Bronx  Brooklyn  Manhattan  Queens  \\\n",
       "0        0        0       0       0      0         0          0       1   \n",
       "1        0        0       0       1      0         0          0       1   \n",
       "2        0        0       0       1      0         1          0       0   \n",
       "3        0        0       0       1      0         1          0       0   \n",
       "4        0        0       0       1      0         1          0       0   \n",
       "\n",
       "   Staten Island  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target and Response Variable, Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health_l') # keep the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521228, 24) (521228,)\n",
      "(130307, 24) (130307,)\n"
     ]
    }
   ],
   "source": [
    "# create targe and response variable\n",
    "y = tree_ml['health'].values\n",
    "X = tree_ml.drop('health', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6804085735992694\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='stratified')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dc_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.68208308072475\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_freq = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf_freq.fit(X_train, y_train)\n",
    "dc_pred_freq = dummy_clf_freq.predict(X_test)\n",
    "\n",
    "print('Accuracy Score: ', dummy_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Under Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random undersampling Counter({'Fair': 20086, 'Good': 20086, 'Poor': 20086})\n"
     ]
    }
   ],
   "source": [
    "random_under = RandomUnderSampler(random_state=42)\n",
    "X_rs, y_rs = random_under.fit_sample(X_train, y_train)\n",
    "\n",
    "print('Random undersampling {}'.format(Counter(y_rs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_rs, y_rs, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.4195127617909655\n",
      "Accuracy Score, Test Set:  0.498133641118833\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_rs, y_rs)\n",
    "logreg_pred = logreg_rs.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_rs, y_rs))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.18      0.18      0.18     24107\n",
      "        Good       0.85      0.55      0.67    132082\n",
      "        Poor       0.07      0.51      0.12      6695\n",
      "\n",
      "    accuracy                           0.50    162884\n",
      "   macro avg       0.37      0.42      0.32    162884\n",
      "weighted avg       0.72      0.50      0.58    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.44818029440562923\n",
      "Accuracy Score, Test Set:  0.37284675893657276\n"
     ]
    }
   ],
   "source": [
    "# using 5 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_rs, y_rs)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_rs, y_rs))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.35      0.44      0.39      6648\n",
      "        Good       0.39      0.35      0.37      6744\n",
      "        Poor       0.39      0.33      0.36      6694\n",
      "\n",
      "    accuracy                           0.37     20086\n",
      "   macro avg       0.38      0.37      0.37     20086\n",
      "weighted avg       0.38      0.37      0.37     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.47542520121722864\n",
      "Accuracy Score, Test Set: 0.4579885071584686\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.32      0.22     24107\n",
      "        Good       0.85      0.49      0.62    132082\n",
      "        Poor       0.07      0.40      0.11      6695\n",
      "\n",
      "    accuracy                           0.46    162884\n",
      "   macro avg       0.36      0.40      0.32    162884\n",
      "weighted avg       0.72      0.46      0.54    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_rs, y_rs)\n",
    "decision_tree_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.4865537981094892\n",
      "Accuracy Score, Test Set: 0.47021806930085214\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.28      0.21     24107\n",
      "        Good       0.85      0.51      0.64    132082\n",
      "        Poor       0.07      0.44      0.11      6695\n",
      "\n",
      "    accuracy                           0.47    162884\n",
      "   macro avg       0.36      0.41      0.32    162884\n",
      "weighted avg       0.72      0.47      0.55    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(random_state=42)\n",
    "rand_forest.fit(X_rs, y_rs)\n",
    "rand_forest_pred = rand_forest.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', rand_forest.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', rand_forest.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, rand_forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 6743  9539  7825]\n",
      " [31654 66923 33505]\n",
      " [ 1627  2143  2925]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, rand_forest_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.7201745212841066\n",
      "Accuracy Score, Test Set: 0.7218327153065985\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.19      0.05      0.08     24107\n",
      "        Good       0.83      0.87      0.85    132082\n",
      "        Poor       0.09      0.26      0.13      6695\n",
      "\n",
      "    accuracy                           0.72    162884\n",
      "   macro avg       0.37      0.39      0.35    162884\n",
      "weighted avg       0.71      0.72      0.71    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_rs, y_rs)\n",
    "gaussian_pred = gaussian.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, gaussian_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5487249591221547\n",
      "Accuracy Score, Test Set: 0.5483841261265686\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.17      0.28      0.21     24107\n",
      "        Good       0.85      0.61      0.71    132082\n",
      "        Poor       0.08      0.35      0.13      6695\n",
      "\n",
      "    accuracy                           0.55    162884\n",
      "   macro avg       0.37      0.41      0.35    162884\n",
      "weighted avg       0.72      0.55      0.61    162884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical = CategoricalNB()\n",
    "categorical.fit(X_rs, y_rs)\n",
    "categorical_pred = categorical.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, categorical_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 6744 11615  5748]\n",
      " [31595 80223 20264]\n",
      " [ 1453  2886  2356]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, categorical_pred)\n",
    "\n",
    "print ('Confusion Matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TomekLinks undersampling Counter({'Good': 422260, 'Fair': 76775, 'Poor': 21425})\n"
     ]
    }
   ],
   "source": [
    "tomek = TomekLinks()\n",
    "X_tomek, y_tomek = tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "print('TomekLinks undersampling {}'.format(Counter(y_tomek)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# X_train_tl, X_test_tl, y_train_tl, y_test_tl = train_test_split(X_tomek, y_tomek, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.8107411727689227\n",
      "Accuracy Score, Test Set:  0.8105473996024772\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.34      0.02      0.03     19285\n",
      "        Good       0.81      1.00      0.90    105666\n",
      "        Poor       0.12      0.00      0.00      5356\n",
      "\n",
      "    accuracy                           0.81    130307\n",
      "   macro avg       0.42      0.34      0.31    130307\n",
      "weighted avg       0.72      0.81      0.73    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42).fit(X_tomek, y_tomek)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7818964192408175\n"
     ]
    }
   ],
   "source": [
    "# using 5 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_tomek, y_tomek)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', knn.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.23      0.10      0.13     23893\n",
      "        Good       0.82      0.95      0.88    131916\n",
      "        Poor       0.28      0.02      0.04      6866\n",
      "\n",
      "    accuracy                           0.78    162675\n",
      "   macro avg       0.44      0.35      0.35    162675\n",
      "weighted avg       0.71      0.78      0.73    162675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_tl, y_pred_knn_tl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8242880275042783\n",
      "Accuracy Score, Test Set: 0.8015993001143453\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.30      0.06      0.10     19285\n",
      "        Good       0.82      0.98      0.89    105666\n",
      "        Poor       0.26      0.03      0.06      5356\n",
      "\n",
      "    accuracy                           0.80    130307\n",
      "   macro avg       0.46      0.36      0.35    130307\n",
      "weighted avg       0.72      0.80      0.74    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42).fit(X_tomek, y_tomek)\n",
    "decision_tree_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8243494209827561\n",
      "Accuracy Score, Test Set: 0.8051677960508645\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.32      0.05      0.08     19285\n",
      "        Good       0.82      0.98      0.89    105666\n",
      "        Poor       0.26      0.04      0.07      5356\n",
      "\n",
      "    accuracy                           0.81    130307\n",
      "   macro avg       0.47      0.36      0.35    130307\n",
      "weighted avg       0.72      0.81      0.74    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(random_state=42).fit(X_tomek, y_tomek)\n",
    "rand_forest_pred = rand_forest.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', rand_forest.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', rand_forest.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, rand_forest_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.7359197894203688\n",
      "Accuracy Score, Test Set: 0.7375889246164826\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.21      0.11      0.14     19285\n",
      "        Good       0.83      0.88      0.86    105666\n",
      "        Poor       0.12      0.20      0.15      5356\n",
      "\n",
      "    accuracy                           0.74    130307\n",
      "   macro avg       0.39      0.39      0.38    130307\n",
      "weighted avg       0.71      0.74      0.72    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB().fit(X_tomek, y_tomek)\n",
    "gaussian_pred = gaussian.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, gaussian_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.8010103064301994\n",
      "Accuracy Score, Test Set: 0.8008625783726123\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.28      0.06      0.10     19285\n",
      "        Good       0.82      0.98      0.89    105666\n",
      "        Poor       0.30      0.04      0.07      5356\n",
      "\n",
      "    accuracy                           0.80    130307\n",
      "   macro avg       0.47      0.36      0.35    130307\n",
      "weighted avg       0.72      0.80      0.74    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical = CategoricalNB().fit(X_tomek, y_tomek)\n",
    "categorical_pred = categorical.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, categorical_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edited Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Good': 217533, 'Poor': 21425, 'Fair': 969})\n"
     ]
    }
   ],
   "source": [
    "enn = EditedNearestNeighbours()\n",
    "X_enn, y_enn = enn.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_enn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# X_train_enn, X_test_enn, y_train_enn, y_test_enn = train_test_split(X_enn, y_enn, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.8058795766919659\n",
      "Accuracy Score, Test Set:  0.806326597957132\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.50      0.00      0.00     19285\n",
      "        Good       0.82      0.99      0.90    105666\n",
      "        Poor       0.21      0.11      0.14      5356\n",
      "\n",
      "    accuracy                           0.81    130307\n",
      "   macro avg       0.51      0.36      0.35    130307\n",
      "weighted avg       0.75      0.81      0.73    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42).fit(X_enn, y_enn)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.9530463311695938\n",
      "Accuracy Score, Test Set:  0.9505291222795128\n"
     ]
    }
   ],
   "source": [
    "# using 5 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_enn, y_enn)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn_enn.score(X_train_enn, y_train_enn))\n",
    "print('Accuracy Score, Test Set: ', knn_enn.score(X_test_enn, y_test_enn))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.62      0.63      0.62       393\n",
      "        Good       0.95      1.00      0.97     78137\n",
      "        Poor       0.91      0.42      0.57      6611\n",
      "\n",
      "    accuracy                           0.95     85141\n",
      "   macro avg       0.83      0.68      0.72     85141\n",
      "weighted avg       0.95      0.95      0.94     85141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_enn, y_pred_knn_enn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.4798437535972741\n",
      "Accuracy Score, Test Set: 0.46924570437505275\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.30      0.01      0.02     19285\n",
      "        Good       0.83      0.55      0.66    105666\n",
      "        Poor       0.05      0.56      0.09      5356\n",
      "\n",
      "    accuracy                           0.47    130307\n",
      "   macro avg       0.39      0.37      0.26    130307\n",
      "weighted avg       0.72      0.47      0.54    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42).fit(X_enn, y_enn)\n",
    "decision_tree_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, decision_tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.72      0.85      0.78       393\n",
      "        Good       0.96      1.00      0.98     78137\n",
      "        Poor       0.91      0.49      0.64      6611\n",
      "\n",
      "    accuracy                           0.96     85141\n",
      "   macro avg       0.86      0.78      0.80     85141\n",
      "weighted avg       0.96      0.96      0.95     85141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_enn, y_pred_decision_tree_enn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.4828923235129348\n",
      "Accuracy Score, Test Set: 0.4738425410760742\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.31      0.01      0.02     19285\n",
      "        Good       0.83      0.55      0.66    105666\n",
      "        Poor       0.05      0.56      0.09      5356\n",
      "\n",
      "    accuracy                           0.47    130307\n",
      "   macro avg       0.40      0.37      0.26    130307\n",
      "weighted avg       0.72      0.47      0.55    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(random_state=42).fit(X_enn, y_enn)\n",
    "rand_forest_pred = rand_forest.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', rand_forest.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', rand_forest.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, rand_forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.76      0.84      0.80       393\n",
      "        Good       0.96      1.00      0.98     78137\n",
      "        Poor       0.94      0.49      0.65      6611\n",
      "\n",
      "    accuracy                           0.96     85141\n",
      "   macro avg       0.89      0.78      0.81     85141\n",
      "weighted avg       0.96      0.96      0.95     85141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_enn, y_pred_forest_enn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.745065499167351\n",
      "Accuracy Score, Test Set: 0.7462147083426063\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.23      0.09      0.13     19285\n",
      "        Good       0.83      0.90      0.86    105666\n",
      "        Poor       0.10      0.17      0.12      5356\n",
      "\n",
      "    accuracy                           0.75    130307\n",
      "   macro avg       0.39      0.38      0.37    130307\n",
      "weighted avg       0.71      0.75      0.72    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB().fit(X_enn, y_enn)\n",
    "gaussian_pred = gaussian.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, gaussian_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.03      0.33      0.06       393\n",
      "        Good       0.94      0.90      0.92     78137\n",
      "        Poor       0.21      0.19      0.20      6611\n",
      "\n",
      "    accuracy                           0.84     85141\n",
      "   macro avg       0.39      0.47      0.39     85141\n",
      "weighted avg       0.88      0.84      0.86     85141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_enn, y_pred_gaussian))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.7955328570222628\n",
      "Accuracy Score, Test Set: 0.7960662128665382\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.30      0.03      0.06     19285\n",
      "        Good       0.82      0.97      0.89    105666\n",
      "        Poor       0.14      0.10      0.12      5356\n",
      "\n",
      "    accuracy                           0.80    130307\n",
      "   macro avg       0.42      0.37      0.35    130307\n",
      "weighted avg       0.72      0.80      0.74    130307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical = CategoricalNB().fit(X_enn, y_enn)\n",
    "categorical_pred = categorical.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train, y_train))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test, y_test))\n",
    "\n",
    "# classification report\n",
    "print('Classification Report \\n')\n",
    "print(classification_report(y_test, categorical_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({'Fair': 26781, 'Good': 26781, 'Poor': 26781})\n"
     ]
    }
   ],
   "source": [
    "nm = NearMiss()\n",
    "X_nm, y_nm = nm.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train_nm, X_test_nm, y_train_nm, y_test_nm = train_test_split(X_nm, y_nm, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.44751647111538906\n",
      "Accuracy Score, Test Set:  0.4448869859603704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg_nm = LogisticRegression().fit(X_train_nm, y_train_nm)\n",
    "y_pred_logreg_nm = logreg_nm.predict(X_test_nm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', logreg_nm.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set: ', logreg_nm.score(X_test_nm, y_test_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41670297 0.42802912 0.41807206 0.43048295 0.46415235]\n",
      "Average 5-Fold CV Score: 0.431487891409546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annatang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "cv_scores_logreg = cross_val_score(logreg_nm, X_nm, y_nm, cv=5)\n",
    "print(cv_scores_logreg)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_logreg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set:  0.44736711087508507\n",
      "Accuracy Score, Test Set:  0.41133127551528426\n"
     ]
    }
   ],
   "source": [
    "# using 6 neighbors\n",
    "knn_nm = KNeighborsClassifier(n_neighbors=6)\n",
    "knn_nm.fit(X_train_nm, y_train_nm)\n",
    "y_pred_knn_nm = knn_nm.predict(X_test_nm)\n",
    "\n",
    "# accuracy scores\n",
    "print('Accuracy Score, Training Set: ', knn_nm.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set: ', knn_nm.score(X_test_nm, y_test_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.36      0.47      0.41      6648\n",
      "        Good       0.41      0.45      0.43      6744\n",
      "        Poor       0.54      0.31      0.39      6694\n",
      "\n",
      "    accuracy                           0.41     20086\n",
      "   macro avg       0.43      0.41      0.41     20086\n",
      "weighted avg       0.43      0.41      0.41     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_nm, y_pred_knn_nm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5063478102129213\n",
      "Accuracy Score, Test Set: 0.46883401374091405\n"
     ]
    }
   ],
   "source": [
    "decision_tree_nm = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_nm.fit(X_train_nm, y_train_nm)\n",
    "y_pred_decision_tree_nm = decision_tree_nm.predict(X_test_nm)\n",
    "\n",
    "# accuracy score\n",
    "\n",
    "print('Accuracy Score, Training Set:', decision_tree_nm.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', decision_tree_nm.score(X_test_nm, y_test_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.43      0.42      6648\n",
      "        Good       0.44      0.60      0.51      6744\n",
      "        Poor       0.66      0.37      0.47      6694\n",
      "\n",
      "    accuracy                           0.47     20086\n",
      "   macro avg       0.50      0.47      0.47     20086\n",
      "weighted avg       0.50      0.47      0.47     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_nm, y_pred_decision_tree_nm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.5062648323016413\n",
      "Accuracy Score, Test Set: 0.47301603106641443\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train_nm, y_train_nm)\n",
    "y_pred_forest_nm = forest.predict(X_test_nm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', forest.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', forest.score(X_test_nm, y_test_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43898189 0.45105483 0.43611924 0.44772218 0.45799104]\n",
      "Average 5-Fold CV Score: 0.4463738342550105\n"
     ]
    }
   ],
   "source": [
    "# cross validation - 5-fold\n",
    "cv_scores_rfc = cross_val_score(forest, X_nm, y_nm, cv=5)\n",
    "\n",
    "print(cv_scores_rfc)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_rfc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.42      0.41      6648\n",
      "        Good       0.44      0.61      0.51      6744\n",
      "        Poor       0.65      0.39      0.48      6694\n",
      "\n",
      "    accuracy                           0.47     20086\n",
      "   macro avg       0.50      0.47      0.47     20086\n",
      "weighted avg       0.50      0.47      0.47     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_nm, y_pred_forest_nm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.4020279801516836\n",
      "Accuracy Score, Test Set: 0.39744100368415813\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB().fit(X_train_nm, y_train_nm)\n",
    "y_pred_g = gaussian.predict(X_test_nm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', gaussian.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', gaussian.score(X_test_nm, y_test_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.30      0.09      0.14      6648\n",
      "        Good       0.37      0.93      0.53      6744\n",
      "        Poor       0.79      0.17      0.28      6694\n",
      "\n",
      "    accuracy                           0.40     20086\n",
      "   macro avg       0.49      0.40      0.32     20086\n",
      "weighted avg       0.49      0.40      0.32     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score, Training Set: 0.45123388154073385\n",
      "Accuracy Score, Test Set: 0.4474758538285373\n"
     ]
    }
   ],
   "source": [
    "categorical = CategoricalNB()\n",
    "categorical.fit(X_train_nm, y_train_nm)\n",
    "y_pred_cnb = categorical.predict(X_test_nm)\n",
    "\n",
    "# accuracy score\n",
    "print('Accuracy Score, Training Set:', categorical.score(X_train_nm, y_train_nm))\n",
    "print('Accuracy Score, Test Set:', categorical.score(X_test_nm, y_test_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.39      0.39      6648\n",
      "        Good       0.43      0.61      0.50      6744\n",
      "        Poor       0.62      0.34      0.44      6694\n",
      "\n",
      "    accuracy                           0.45     20086\n",
      "   macro avg       0.48      0.45      0.44     20086\n",
      "weighted avg       0.48      0.45      0.44     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rs, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
