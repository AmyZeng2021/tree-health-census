{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Overview - Under Sampling Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import (KFold, \n",
    "                                     cross_val_score, \n",
    "                                     GridSearchCV, \n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (classification_report,\n",
    "                             confusion_matrix)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import imblearn\n",
    "from imblearn.under_sampling import (RandomUnderSampler,\n",
    "                                     TomekLinks,\n",
    "                                     EditedNearestNeighbours,\n",
    "                                     NearMiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tree_ml.csv', index_col=0) # import data\n",
    "tree = data.copy() # save a copy of data as tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>health_l</th>\n",
       "      <th>num_problems</th>\n",
       "      <th>tree_dbh</th>\n",
       "      <th>root_stone_l</th>\n",
       "      <th>root_grate_l</th>\n",
       "      <th>root_other_l</th>\n",
       "      <th>trunk_wire_l</th>\n",
       "      <th>trnk_light_l</th>\n",
       "      <th>trnk_other_l</th>\n",
       "      <th>...</th>\n",
       "      <th>OnCurb</th>\n",
       "      <th>Harmful</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Unsure</th>\n",
       "      <th>Damage</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Good</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  health  health_l  num_problems  tree_dbh  root_stone_l  root_grate_l  \\\n",
       "0   Fair         1             0         3             0             0   \n",
       "1   Fair         1             1        21             1             0   \n",
       "2   Good         2             0         3             0             0   \n",
       "3   Good         2             1        10             1             0   \n",
       "4   Good         2             1        21             1             0   \n",
       "\n",
       "   root_other_l  trunk_wire_l  trnk_light_l  trnk_other_l  ...  OnCurb  \\\n",
       "0             0             0             0             0  ...       1   \n",
       "1             0             0             0             0  ...       1   \n",
       "2             0             0             0             0  ...       1   \n",
       "3             0             0             0             0  ...       1   \n",
       "4             0             0             0             0  ...       1   \n",
       "\n",
       "   Harmful  Helpful  Unsure  Damage  Bronx  Brooklyn  Manhattan  Queens  \\\n",
       "0        0        0       0       0      0         0          0       1   \n",
       "1        0        0       0       1      0         0          0       1   \n",
       "2        0        0       0       1      0         1          0       0   \n",
       "3        0        0       0       1      0         1          0       0   \n",
       "4        0        0       0       1      0         1          0       0   \n",
       "\n",
       "   Staten Island  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651535, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  separate variables using train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ml = tree.drop(columns='health_l') # keep the categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488651, 24) (488651,)\n",
      "(162884, 24) (162884,)\n"
     ]
    }
   ],
   "source": [
    "# target variable = health\n",
    "y = tree_ml['health'].values\n",
    "X = tree_ml.drop('health', axis=1).values\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline - DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dummy classifier is our baseline, it makes predictions based on simply guessing. We use these results as comparisons to real classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_frequent 0.8108960978364972\n",
      "stratified 0.6815525159008865\n",
      "uniform 0.3338879202377152\n",
      "constant 0.8108960978364972\n"
     ]
    }
   ],
   "source": [
    "strategies = ['most_frequent', 'stratified', 'uniform', 'constant'] # strategies available\n",
    "  \n",
    "for s in strategies: \n",
    "    if s =='constant': \n",
    "        dummy_classifier = DummyClassifier(strategy=s, random_state=42, constant='Good') \n",
    "    else: \n",
    "        dummy_classifier = DummyClassifier(strategy=s, random_state=42) \n",
    "    dummy_classifier.fit(X_train, y_train) \n",
    "    score = dummy_classifier.score(X_test, y_test) \n",
    "    print(s, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "def logreg(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    print('Logistic Regression \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set: ', logreg.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set: ', logreg.score(X_test, y_test))\n",
    "    print()\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier\n",
    "def knn(X_train, X_test, y_train, y_test):\n",
    "    # using 6 neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print('KNN Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set: ', knn.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set: ', knn.score(X_test, y_test))\n",
    "    print()\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classificatin report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "def decision_tree(X_train, X_test, y_train, y_test):\n",
    "    decision_tree = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    \n",
    "    print('Decision Tree Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', decision_tree.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', decision_tree.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print('Random Forest Classifier \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', rf.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', rf.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian naive bayes\n",
    "def gaussian(X_train, X_test, y_train, y_test):\n",
    "    gaussian = GaussianNB().fit(X_train, y_train)\n",
    "    y_pred = gaussian.predict(X_test)\n",
    "    \n",
    "    print('Gaussian Naive Bayes \\n')\n",
    "    \n",
    "    # accuracy scores\n",
    "    print('Accuracy Score, Training Set:', gaussian.score(X_train, y_train))\n",
    "    print('Accuracy Score, Test Set:', gaussian.score(X_test, y_test))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "    print()\n",
    "    \n",
    "    # classification report\n",
    "    print('Classification Report \\n')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Under Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random undersampling Counter({'Fair': 26781, 'Good': 26781, 'Poor': 26781})\n",
      "(60257, 24) (60257,)\n",
      "(20086, 24) (20086,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "random_under = RandomUnderSampler(random_state=42)\n",
    "X_rs, y_rs = random_under.fit_sample(X, y)\n",
    "\n",
    "print('Random undersampling {}'.format(Counter(y_rs)))\n",
    "\n",
    "# train test split\n",
    "X_train_rs, X_test_rs, y_train_rs, y_test_rs = train_test_split(X_rs, y_rs, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_rs.shape, y_train_rs.shape)\n",
    "print(X_test_rs.shape, y_test_rs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.41839122425610303\n",
      "Accuracy Score, Test Set:  0.4137707856218261\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1141 2785 2722]\n",
      " [ 940 3552 2252]\n",
      " [ 880 2196 3618]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.39      0.17      0.24      6648\n",
      "        Good       0.42      0.53      0.47      6744\n",
      "        Poor       0.42      0.54      0.47      6694\n",
      "\n",
      "    accuracy                           0.41     20086\n",
      "   macro avg       0.41      0.41      0.39     20086\n",
      "weighted avg       0.41      0.41      0.39     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.44910964701196543\n",
      "Accuracy Score, Test Set:  0.3725480434133227\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3141 1950 1557]\n",
      " [3106 2374 1264]\n",
      " [3016 1710 1968]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.34      0.47      0.39      6648\n",
      "        Good       0.39      0.35      0.37      6744\n",
      "        Poor       0.41      0.29      0.34      6694\n",
      "\n",
      "    accuracy                           0.37     20086\n",
      "   macro avg       0.38      0.37      0.37     20086\n",
      "weighted avg       0.38      0.37      0.37     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.543107024909969\n",
      "Accuracy Score, Test Set: 0.4008762322015334\n",
      "Confusion Matrix: \n",
      " [[2043 2631 1974]\n",
      " [1791 3371 1582]\n",
      " [1734 2322 2638]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.37      0.31      0.33      6648\n",
      "        Good       0.40      0.50      0.45      6744\n",
      "        Poor       0.43      0.39      0.41      6694\n",
      "\n",
      "    accuracy                           0.40     20086\n",
      "   macro avg       0.40      0.40      0.40     20086\n",
      "weighted avg       0.40      0.40      0.40     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.543040642580945\n",
      "Accuracy Score, Test Set: 0.4056058946529921\n",
      "Confusion Matrix: \n",
      " [[1801 2573 2274]\n",
      " [1532 3372 1840]\n",
      " [1500 2220 2974]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.37      0.27      0.31      6648\n",
      "        Good       0.41      0.50      0.45      6744\n",
      "        Poor       0.42      0.44      0.43      6694\n",
      "\n",
      "    accuracy                           0.41     20086\n",
      "   macro avg       0.40      0.41      0.40     20086\n",
      "weighted avg       0.40      0.41      0.40     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.39248552035448164\n",
      "Accuracy Score, Test Set: 0.3930100567559494\n",
      "Confusion Matrix: \n",
      " [[ 535 4812 1301]\n",
      " [ 446 5728  570]\n",
      " [ 409 4654 1631]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.08      0.13      6648\n",
      "        Good       0.38      0.85      0.52      6744\n",
      "        Poor       0.47      0.24      0.32      6694\n",
      "\n",
      "    accuracy                           0.39     20086\n",
      "   macro avg       0.41      0.39      0.33     20086\n",
      "weighted avg       0.41      0.39      0.33     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_rs, X_test_rs, y_train_rs, y_test_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TomekLinks undersampling Counter({'Good': 527892, 'Fair': 96026, 'Poor': 26781})\n",
      "(488024, 24) (488024,)\n",
      "(162675, 24) (162675,)\n"
     ]
    }
   ],
   "source": [
    "tomek = TomekLinks()\n",
    "X_tomek, y_tomek = tomek.fit_resample(X, y)\n",
    "\n",
    "print('TomekLinks undersampling {}'.format(Counter(y_tomek)))\n",
    "\n",
    "# train test split\n",
    "X_train_tl, X_test_tl, y_train_tl, y_test_tl = train_test_split(X_tomek, y_tomek, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_tl.shape, y_train_tl.shape)\n",
    "print(X_test_tl.shape, y_test_tl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.8112920676032326\n",
      "Accuracy Score, Test Set:  0.8104933148916551\n",
      "\n",
      "Confusion Matrix: \n",
      " [[   394  23498      1]\n",
      " [   461 131452      3]\n",
      " [   389   6476      1]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.32      0.02      0.03     23893\n",
      "        Good       0.81      1.00      0.90    131916\n",
      "        Poor       0.20      0.00      0.00      6866\n",
      "\n",
      "    accuracy                           0.81    162675\n",
      "   macro avg       0.44      0.34      0.31    162675\n",
      "weighted avg       0.72      0.81      0.73    162675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_tl, X_test_tl, y_train_tl, y_test_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.800884792551186\n",
      "Accuracy Score, Test Set:  0.7901152604887045\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  2030  21718    145]\n",
      " [  5402 126352    162]\n",
      " [   735   5981    150]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.25      0.08      0.13     23893\n",
      "        Good       0.82      0.96      0.88    131916\n",
      "        Poor       0.33      0.02      0.04      6866\n",
      "\n",
      "    accuracy                           0.79    162675\n",
      "   macro avg       0.47      0.35      0.35    162675\n",
      "weighted avg       0.72      0.79      0.74    162675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_tl, X_test_tl, y_train_tl, y_test_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.8255208760224907\n",
      "Accuracy Score, Test Set: 0.8012417396649761\n",
      "Confusion Matrix: \n",
      " [[  1413  22231    249]\n",
      " [  2833 128726    357]\n",
      " [   544   6119    203]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.29      0.06      0.10     23893\n",
      "        Good       0.82      0.98      0.89    131916\n",
      "        Poor       0.25      0.03      0.05      6866\n",
      "\n",
      "    accuracy                           0.80    162675\n",
      "   macro avg       0.46      0.35      0.35    162675\n",
      "weighted avg       0.72      0.80      0.74    162675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_tl, X_test_tl, y_train_tl, y_test_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.8255167778633837\n",
      "Accuracy Score, Test Set: 0.805489472875365\n",
      "Confusion Matrix: \n",
      " [[  1077  22548    268]\n",
      " [  1814 129715    387]\n",
      " [   409   6216    241]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.33      0.05      0.08     23893\n",
      "        Good       0.82      0.98      0.89    131916\n",
      "        Poor       0.27      0.04      0.06      6866\n",
      "\n",
      "    accuracy                           0.81    162675\n",
      "   macro avg       0.47      0.35      0.34    162675\n",
      "weighted avg       0.72      0.81      0.74    162675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_tl, X_test_tl, y_train_tl, y_test_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.734986394111765\n",
      "Accuracy Score, Test Set: 0.7342800061472261\n",
      "Confusion Matrix: \n",
      " [[  2926  18145   2822]\n",
      " [ 10284 115264   6368]\n",
      " [   746   4861   1259]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.21      0.12      0.15     23893\n",
      "        Good       0.83      0.87      0.85    131916\n",
      "        Poor       0.12      0.18      0.15      6866\n",
      "\n",
      "    accuracy                           0.73    162675\n",
      "   macro avg       0.39      0.39      0.38    162675\n",
      "weighted avg       0.71      0.73      0.72    162675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_tl, X_test_tl, y_train_tl, y_test_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edited Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Good': 312229, 'Poor': 26781, 'Fair': 1553})\n",
      "(255422, 24) (255422,)\n",
      "(85141, 24) (85141,)\n"
     ]
    }
   ],
   "source": [
    "enn = EditedNearestNeighbours()\n",
    "X_enn, y_enn = enn.fit_resample(X, y)\n",
    "\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_enn)))\n",
    "\n",
    "# train test split\n",
    "X_train_enn, X_test_enn, y_train_enn, y_test_enn = train_test_split(X_enn, y_enn, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_enn.shape, y_train_enn.shape)\n",
    "print(X_test_enn.shape, y_test_enn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.9208603800768923\n",
      "Accuracy Score, Test Set:  0.9221174287358617\n",
      "\n",
      "Confusion Matrix: \n",
      " [[    1   288   104]\n",
      " [    2 77852   283]\n",
      " [   10  5944   657]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.08      0.00      0.00       393\n",
      "        Good       0.93      1.00      0.96     78137\n",
      "        Poor       0.63      0.10      0.17      6611\n",
      "\n",
      "    accuracy                           0.92     85141\n",
      "   macro avg       0.54      0.37      0.38     85141\n",
      "weighted avg       0.90      0.92      0.89     85141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_enn, X_test_enn, y_train_enn, y_test_enn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.9552231209527762\n",
      "Accuracy Score, Test Set:  0.9516331732067982\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  254    57    82]\n",
      " [   22 77848   267]\n",
      " [  117  3573  2921]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.65      0.65      0.65       393\n",
      "        Good       0.96      1.00      0.98     78137\n",
      "        Poor       0.89      0.44      0.59      6611\n",
      "\n",
      "    accuracy                           0.95     85141\n",
      "   macro avg       0.83      0.69      0.74     85141\n",
      "weighted avg       0.95      0.95      0.94     85141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_enn, X_test_enn, y_train_enn, y_test_enn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.965269240707535\n",
      "Accuracy Score, Test Set: 0.9565896571569514\n",
      "Confusion Matrix: \n",
      " [[  334    23    36]\n",
      " [   19 77849   269]\n",
      " [  112  3237  3262]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.72      0.85      0.78       393\n",
      "        Good       0.96      1.00      0.98     78137\n",
      "        Poor       0.91      0.49      0.64      6611\n",
      "\n",
      "    accuracy                           0.96     85141\n",
      "   macro avg       0.86      0.78      0.80     85141\n",
      "weighted avg       0.96      0.96      0.95     85141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_enn, X_test_enn, y_train_enn, y_test_enn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.965269240707535\n",
      "Accuracy Score, Test Set: 0.957799415087913\n",
      "Confusion Matrix: \n",
      " [[  330    23    40]\n",
      " [    6 77980   151]\n",
      " [   96  3277  3238]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.76      0.84      0.80       393\n",
      "        Good       0.96      1.00      0.98     78137\n",
      "        Poor       0.94      0.49      0.65      6611\n",
      "\n",
      "    accuracy                           0.96     85141\n",
      "   macro avg       0.89      0.78      0.81     85141\n",
      "weighted avg       0.96      0.96      0.95     85141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_enn, X_test_enn, y_train_enn, y_test_enn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.843854483952048\n",
      "Accuracy Score, Test Set: 0.84417613135857\n",
      "Confusion Matrix: \n",
      " [[  128    71   194]\n",
      " [ 3137 70512  4488]\n",
      " [  750  4627  1234]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.03      0.33      0.06       393\n",
      "        Good       0.94      0.90      0.92     78137\n",
      "        Poor       0.21      0.19      0.20      6611\n",
      "\n",
      "    accuracy                           0.84     85141\n",
      "   macro avg       0.39      0.47      0.39     85141\n",
      "weighted avg       0.88      0.84      0.86     85141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_enn, X_test_enn, y_train_enn, y_test_enn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({'Fair': 26781, 'Good': 26781, 'Poor': 26781})\n",
      "(60257, 24) (60257,)\n",
      "(20086, 24) (20086,)\n"
     ]
    }
   ],
   "source": [
    "nm = NearMiss()\n",
    "X_nm, y_nm = nm.fit_resample(X, y)\n",
    "print('Resampled dataset shape: {}'.format(Counter(y_nm)))\n",
    "\n",
    "# train test split\n",
    "X_train_nm, X_test_nm, y_train_nm, y_test_nm = train_test_split(X_nm, y_nm, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train_nm.shape, y_train_nm.shape)\n",
    "print(X_test_nm.shape, y_test_nm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elite\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Accuracy Score, Training Set:  0.4476492357734371\n",
      "Accuracy Score, Test Set:  0.44538484516578714\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2515 3179  954]\n",
      " [1979 4064  701]\n",
      " [2042 2285 2367]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.38      0.38      0.38      6648\n",
      "        Good       0.43      0.60      0.50      6744\n",
      "        Poor       0.59      0.35      0.44      6694\n",
      "\n",
      "    accuracy                           0.45     20086\n",
      "   macro avg       0.47      0.44      0.44     20086\n",
      "weighted avg       0.47      0.45      0.44     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg(X_train_nm, X_test_nm, y_train_nm, y_test_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier \n",
      "\n",
      "Accuracy Score, Training Set:  0.44540883216887667\n",
      "Accuracy Score, Test Set:  0.4092402668525341\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3267 2377 1004]\n",
      " [3119 2818  807]\n",
      " [2794 1765 2135]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.36      0.49      0.41      6648\n",
      "        Good       0.40      0.42      0.41      6744\n",
      "        Poor       0.54      0.32      0.40      6694\n",
      "\n",
      "    accuracy                           0.41     20086\n",
      "   macro avg       0.43      0.41      0.41     20086\n",
      "weighted avg       0.43      0.41      0.41     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn(X_train_nm, X_test_nm, y_train_nm, y_test_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5063478102129213\n",
      "Accuracy Score, Test Set: 0.46883401374091405\n",
      "Confusion Matrix: \n",
      " [[2891 2991  766]\n",
      " [2178 4076  490]\n",
      " [2118 2126 2450]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.40      0.43      0.42      6648\n",
      "        Good       0.44      0.60      0.51      6744\n",
      "        Poor       0.66      0.37      0.47      6694\n",
      "\n",
      "    accuracy                           0.47     20086\n",
      "   macro avg       0.50      0.47      0.47     20086\n",
      "weighted avg       0.50      0.47      0.47     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree(X_train_nm, X_test_nm, y_train_nm, y_test_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier \n",
      "\n",
      "Accuracy Score, Training Set: 0.5062648323016413\n",
      "Accuracy Score, Test Set: 0.47301603106641443\n",
      "Confusion Matrix: \n",
      " [[2795 3007  846]\n",
      " [2076 4124  544]\n",
      " [1968 2144 2582]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.41      0.42      0.41      6648\n",
      "        Good       0.44      0.61      0.51      6744\n",
      "        Poor       0.65      0.39      0.48      6694\n",
      "\n",
      "    accuracy                           0.47     20086\n",
      "   macro avg       0.50      0.47      0.47     20086\n",
      "weighted avg       0.50      0.47      0.47     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest(X_train_nm, X_test_nm, y_train_nm, y_test_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes \n",
      "\n",
      "Accuracy Score, Training Set: 0.4020279801516836\n",
      "Accuracy Score, Test Set: 0.39744100368415813\n",
      "Confusion Matrix: \n",
      " [[ 589 5864  195]\n",
      " [ 383 6249  112]\n",
      " [ 981 4568 1145]]\n",
      "\n",
      "Classification Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.30      0.09      0.14      6648\n",
      "        Good       0.37      0.93      0.53      6744\n",
      "        Poor       0.79      0.17      0.28      6694\n",
      "\n",
      "    accuracy                           0.40     20086\n",
      "   macro avg       0.49      0.40      0.32     20086\n",
      "weighted avg       0.49      0.40      0.32     20086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train_nm, X_test_nm, y_train_nm, y_test_nm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
